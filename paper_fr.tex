\documentclass[letterpaper,twocolumn,10pt]{article}
\usepackage{usenix2019_v3}
%\documentclass[conference]{IEEEtran}
%\newcommand{\subparagraph}{}
%\usepackage[letterpaper, total={6.5in, 9in}, columnsep=0.25in]{geometry}
%\usepackage[letterpaper, total={7in, 9in}, columnsep=0.33in]{geometry}
%\usepackage[letterpaper, total={7.15in, 9.5in}, columnsep=0.15in]{geometry}
\newcommand{\tronly}[2]{#1}
\usepackage{newtxtext}
\usepackage{appendix}
\tronly{}{%
%\usepackage{microtype}
\usepackage[subtle]{savetrees}
}
\usepackage{comment}
\usepackage{mathtools}
\usepackage{fancyvrb}
\DeclarePairedDelimiter{\ceil}{\lceil}{\rceil}
\DeclarePairedDelimiter{\floor}{\lfloor}{\rfloor}

\setlength{\parskip}{0pt}
\setlength{\abovedisplayskip}{3pt}
\setlength{\belowdisplayskip}{3pt}
\setlength{\textfloatsep}{2pt plus 1.0pt minus 1.0pt}
\setlength{\floatsep}{2pt plus 1.0pt minus 1.0pt}
%\setlength{\textfloatsep}{1pt plus 0.0pt minus 1.0pt}
%\setlength{\floatsep}{1pt plus 0.0pt minus 1.0pt}

\usepackage{cite}
\usepackage{paralist}
%\usepackage[hyphens]{url}
\usepackage[compact]{titlesec}
\usepackage{enumitem}
\setdefaultleftmargin{0em}{}{}{}{}{}
\setdefaultitem{{}}{}{}{}
\setlist[itemize]{leftmargin=*}
\setlist[enumerate]{leftmargin=*}
%\expandafter\def\expandafter\UrlBreaks\expandafter{\UrlBreaks%  save the current one
%\do\a\do\b\do\c\do\d\do\e\do\f\do\g\do\h\do\i\do\j%
%\do\k\do\l\do\m\do\n\do\o\do\p\do\q\do\r\do\s\do\t%
%\do\u\do\v\do\w\do\x\do\y\do\z\do\A\do\B\do\C\do\D%
%\do\E\do\F\do\G\do\H\do\I\do\J\do\K\do\L\do\M\do\N%
%\do\Oh\do\P\do\Q\do\R\do\S\do\T\do\U\do\V\do\W\do\X%
%\do\Y\do\Z}
\usepackage{caption}
% \captionsetup[figure]{font=small,labelfont=small,skip=3pt}
\usepackage[normalem]{ulem}
\usepackage{amsmath}
\usepackage{bbm}
\usepackage{thmtools, thm-restate}
\usepackage{mathrsfs}
\usepackage{amssymb}
\usepackage{tikz}
\usepackage{dsfont}
\usepackage{capt-of}
\usepackage{algorithmicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsthm}
\usepackage[makeroom]{cancel}
\usepackage{datetime}
\renewcommand\ttdefault{cmtt}
\graphicspath{{./figures}}
\DeclareMathOperator*{\argmin}{arg\,min}
\DeclareMathOperator*{\argmax}{arg\,max}
\newcommand{\Oh}[1]{O(#1)}
\let\oldemptyset\emptyset
\let\emptyset\varnothing
% New definitions
\algnewcommand\algorithmicswitch{\textbf{switch}}
\algnewcommand\algorithmiccase{\textbf{case}}
\algnewcommand\algorithmicassert{\texttt{assert}}
\algnewcommand\Assert[1]{\State \algorithmicassert(#1)}%
% New "environments"
\algdef{SE}[SWITCH]{Switch}{EndSwitch}[1]{\algorithmicswitch\ #1\ \algorithmicdo}{\algorithmicend\ \algorithmicswitch}%
\algdef{SE}[CASE]{Case}{EndCase}[1]{\algorithmiccase\ #1}{\algorithmicend\ \algorithmiccase}%
\algtext*{EndSwitch}%
\algtext*{EndCase}%⇧
\algnewcommand\algorithmiccontinue{\textbf{continue}}
\algnewcommand\algorithmicbreak{\textbf{break}}
\algnewcommand\Continue{\algorithmiccontinue}
\algnewcommand\Break{\algorithmicbreak}
\newcommand{\editremove}[1]{{\color{red}\sout{#1}}}
\newcommand{\editinsert}[1]{{\color{blue}#1}}
\newcommand{\editchange}[1]{{\color{orange}#1}}
\newcommand\ddfrac[2]{\frac{\displaystyle #1}{\displaystyle #2}}

%O \newtheorem{theorem}{Theorem}
\newtheorem{theorem}{Théorème}
%O \newtheorem{lemma}[theorem]{Lemma}
\newtheorem{lemma}[theorem]{Lemme}
\newtheorem{conjecture}[theorem]{Conjecture}
%O \theoremstyle{definition}
\theoremstyle{definition}
%O \newtheorem{definition}{Definition}[section]
\newtheorem{definition}{Définition}[section]

\newcommand\blfootnote[1]{%
  \begingroup
  \renewcommand\thefootnote{}\footnote{#1}%
  \addtocounter{footnote}{-1}%
  \endgroup
}

% Default section titles for French version
\renewcommand{\abstractname}{Résumé}
\renewcommand{\refname}{Références}
\renewcommand{\proofname}{Preuve}
\settimeformat{hhmmsstime}
\mmddyyyydate
\title{
%O \Large\bf Scalable and Probabilistic Leaderless BFT Consensus through Metastability}
\Large\bf Consensus BFT sans dirigeant, extensible et probabiliste, par métastabilité}
\author{%
\tronly{%
Team~Rocket,
Maofan~Yin,
Kevin~Sekniqi,
Robbert~van~Renesse,
Emin~G\"un~Sirer\\
Cornell University\textsuperscript{*}
}{%
Anonymous Submission 134
}
}
\date{}

\tronly{%
\usepackage[hang]{footmisc}
\setlength\footnotemargin{0em}
}

\begin{document}
\maketitle
\tronly{%
\blfootnote{%
%O \textsuperscript{*}\emph{Blasts off at the speed of light!} --- Team Rocket\\
\textsuperscript{*}\emph{À la vitesse de la lumière !} --- Team Rocket\\
%O An earlier version of this paper published on May 16th 2018, IPFS, was titled \emph{Snowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies}.
Une version antérieure de cet article, publié le 16 mai 2018, IPFS, était intitulée \emph{Snowflake to Avalanche: A Novel Metastable Consensus Protocol Family for Cryptocurrencies}.

%Proof of Team Rocket: \verb|SHA256("avalanche ted yin kevin sekniqi robbert van |\\
%\verb|renesse emin gun sirer\n") = 0x 8a5d 2d32 e68b c500 36e4 |\\
%\verb|d086 0446 17fe 4a0a 0296 b274 999b a568 ea92 da46 d533|
}
}{}

\begin{abstract}
%O This paper introduces a family of leaderless Byzantine fault tolerance protocols, built around a metastable mechanism via network subsampling.
Cet article présente une famille de protocoles à tolérance de faute byzantine sans dirigeant, bâtis autour d'un mécanisme métastable via sous-échantillonnage réseau.
%O These protocols provide a strong probabilistic safety guarantee in the presence of Byzantine adversaries while their concurrent and leaderless nature enables them to achieve high throughput and scalability.
Ces protocoles fournissent une forte garantie de sûreté probabiliste en présence d'adversaires byzantins, tandis que leur nature simultanée et sans dirigeant leur permet d'être performants et extensibles.
%O Unlike blockchains that rely on proof-of-work, they are quiescent and green.
Contrairement aux blockchains fondées sur la preuve de travail (\emph{proof-of-work}), ils sont économes et écologiques.
%O Unlike traditional consensus protocols where one or more nodes typically process linear bits in the number of total nodes per decision, no node processes more than logarithmic bits. It does not require accurate knowledge of all participants and exposes new possible tradeoffs and improvements in safety and liveness for building consensus protocols.
Contrairement aux protocoles de consensus traditionnels où un ou plusieurs nœuds traitent typiquement des bits de manière linéaire dans les nombres de nœuds totaux par décision, aucun nœud ne les traite plus que de manière logarithmique. HOULA
%Finally, unlike traditional consensus protocols and similar to longest-chain protocols, our protocols provide increase in both liveness and safety guarantees when the observed adversarial presence decreases below the maximal expected bound. 

%where $k$ is dependent on the security requirements of the system.
% require $O(n^{2})$
% communication, their communication complexity ranges from
% $O(kn\log n)$
% to
% $O(kn)$
% for some security parameter $k \ll n$. \Jon{This sentence led me to assuem that the two ``best'' protocols were both going to be important; that there would be a reason to use the $O(kn\log n)$ version despite its poorer aymptotics. But when I got to later pages, I see you're only discussing Avalanche after all; the other algorithms are purely steps on the pedagogical garden path, right? Maybe remove the reference to the intermediate steps from the abstract?} 

%O The paper describes the Snow protocol family, analyzes its guarantees, and describes how it can be used to construct the core of an internet-scale electronic payment system called Avalanche, which is evaluated in a large scale deployment.
Cet article décrit la famille de protocoles Snow, analyse ses garanties et décrit la manière dont il peut être utilisé pour construire le cœur d'un système de paiement électronique à l'échelle de l'internet appelé Avalanche, qui est évalué lors d'un déploiement à grande échelle.
%O Experiments demonstrate that the system can achieve high throughput (3400 tps), provide low confirmation latency (1.35 sec), and scale well compared to existing systems that deliver similar functionality. For our implementation and setup, the bottleneck of the system is in transaction verification.
Les expériences démontrent que le système peut atteindre un haut débit (3400~tps), fournir une faible latence de confirmation (1,35~s) et correctement passer à l'échelle par rapport à d'autres systèmes offrant des fonctionnalités similaires. Le goulet d'étranglement du système dans l'implémentation et la configuration retenue est la vérification des transations.
\end{abstract}

\section{Introduction}

%O Achieving agreement among a set of distributed hosts lies at the core of countless applications, ranging from Internet-scale services that serve billions of people~\cite{Burrows06,HuntKJR10} to cryptocurrencies worth billions of dollars~\cite{marketcapcryptocurrency}.
L'accord parmi un ensemble d'hôtes distribués se retrouve au cœur d'innombrables applications allant de services à l'échelle de l'Internet servant des milliards de gens~\cite{Burrows06,HuntKJR10} à des cryptomonnaies valant des milliards de dollars~\cite{marketcapcryptocurrency}.
%O To date, there have been two main families of solutions to this problem.
À ce jour, il existe deux familles principales de solutions à ce problème.
%O Traditional consensus protocols %, exemplified by PBFT~\cite{castro1999practical},
%O rely on all-to-all communication to ensure that all correct nodes reach the same decisions with absolute certainty.
Les protocoles de consensus traditionnels
sont fondés sur une communication entre chaque pair pour s'assurer que tous les nœuds correct arrivent aux mêmes décisions avec une certitude absolue.
%Because they usually require quadratic communication overhead and accurate knowledge of membership, they have been difficult to scale
%O to large numbers of participants.
Comme ils impliquent en général un nombre de communication exponentiel et une connaissance exacte des participants, il s'est avéré difficile de l'étendre
à de nombreux participants.
%O On the other hand, Nakamoto consensus protocols~\cite{nakamoto2008bitcoin,GarayKL15, PassSS17, SompolinskyZ15, SompolinskyLZ16, SompolinskyZ18, BentovHMN17, EyalGSR16,Kokoris-KogiasJ16,PassS16a, PassS18} have become popular with the rise of Bitcoin.
D'un autre côté, les protocoles de consensus Nakamoto~\cite{nakamoto2008bitcoin,GarayKL15, PassSS17, SompolinskyZ15, SompolinskyLZ16, SompolinskyZ18, BentovHMN17, EyalGSR16,Kokoris-KogiasJ16,PassS16a, PassS18} ont été popularisés par Bitcoin.
%O These protocols provide a probabilistic safety guarantee: Nakamoto consensus decisions may revert with some probability $\varepsilon$.
Ces protocoles fournissent une garantie de sûreté probabiliste : les décisions par consensus Nakamoto peuvent s'inverser avec une certaine probabilité $\varepsilon$.
%O A protocol parameter allows this probability to be rendered arbitrarily small, enabling high-value financial systems to be constructed on this foundation.
Un paramètre du protocole permet d'abaisser à volonté cette probabilité, ce qui permet de bâtir des systèmes financiers de grande valeur sur ces fondations.
%O This family is a natural fit for open, permissionless settings where any node can join the system at any time.
Cette famille est faite pour des configurations ouvertes et en libre accès où tout nœud peut rejoindre le système à tout moment.
%O Yet, these protocols are costly, wasteful, and limited in performance.
Cependant ces protocoles sont coûteux, gaspilleurs et limités en performance.
%O By construction, they cannot quiesce: their security relies on constant participation by miners, even when there are no decisions to be made.
Par construction, ils sont tenus de fonctionner même à vide : leur sécurité se base sur une participation constante des mineurs, même quand aucune décision ne doit être prise.
%O Bitcoin currently consumes around 63.49 TWh/year~\cite{bitcoinpower}, about twice as all of Denmark~\cite{denmarkpower}.
Bitcoin consomme actuellement autour de 63.49 TWh/an~\cite{bitcoinpower}, environ deux fois l'énergie consommée par le Danemark~\cite{denmarkpower}.
%O Moreover, these protocols suffer from an inherent scalability bottleneck that is difficult to overcome through simple reparameterization~\cite{CromanDEGJKMSSS16}. % \Jon{I wanted the paper to expand on this point, but I missed it.}
De plus, ces protocoles souffrent d'un goulet d'étranglement intrinsèque pour le passage à l'échelle, qui est difficile à dépasser par la simple reparamétrisation~\cite{CromanDEGJKMSSS16}.
%O This paper introduces a new family of consensus protocols called Snow.
Cet article présente une nouvelle famille de protocoles de consensus appelés Snow.
%O Inspired by gossip algorithms, this family gains its properties through a deliberately metastable mechanism.
Inspirée par les algorithmes de \emph{gossip} ou bavardage, cette famille possède des propriétés grâce à un mécanisme délibérément métastable.
%O Specifically, the system operates by repeatedly sampling the network at random, and steering correct nodes towards a common outcome.
En particulier, le système opère en échantillonnant répétitivement le réseau au hasard, et en dirigeant les nœuds corrects vers un résultat commun.
%O Analysis shows that this metastable mechanism is powerful: it can move a large network to an irreversible state quickly, where the irreversibility implies that a sufficiently large portion of the network has accepted a proposal and a conflicting proposal will not be accepted with any higher than negligible ($\varepsilon$) probability. 
L'analyse montre que ce mécanisme métastable est puissant : il peut rapidement changer l'état d'un vaste réseau de manière irréversible, où l'irréversibilité implique qu'une part suffisamment importante du réseau a accepté une proposition et qu'une proposition différente ne sera acceptée qu'avec une probabilité au maximum négligeable.
%{\color{red} We should clarify this.  The current statement is too strong.}
% though it is not always guaranteed to do so.
% \Jon{Not universal in that some applications require a hard guarantee?}

%O Similar to Nakamoto consensus, the Snow protocol family provides a probabilistic safety guarantee, using a tunable security parameter that can render the possibility of a consensus failure arbitrarily small.
De même que le consensus Nakamoto, la famille des protocoles Snow fournissent une garantie de sûreté probabiliste, grâce à un paramètre des sécurité réglable qui peut amenuiser à volonter la possibilité d'un échec du consensus.
%O Unlike Nakamoto consensus, the protocols are green, quiescent and efficient; they do not rely on proof-of-work~\cite{DworkN92} and do not consume energy when there are no decisions to be made.
Contrairement au consensus Nakamoto, ces protocoles sont écologiques, économes et efficients ; ils ne dépendent pas d'une preuve de travail\cite{DworkN92} et ne consomment pas d'énergie quand il n'y a pas de décision à prendre.
%0 The efficiency of the protocols stems partly from removing the leader bottleneck: each node requires $\Oh{1}$ communication overhead per round and $\Oh{\log{n}}$ rounds in expectation, whereas classical consensus protocols have one or more nodes that require $\Oh{n}$ communication per round (phase).
L'efficacité des protocoles provient en partie de l'élimination du goulet d'étranglement des dirigeants : chaque nœud ne demande qu'un nombre de communications correspondant à $\Oh{1}$ par tour et une prévision de $\Oh{\log{n}}$ tours, alors que, dans les protocoles de consensus classique, un ou plusieurs nœuds requièrent $\Oh{n}$ communications par tour.
%O Further, the Snow family tolerates discrepancies in knowledge of membership, as we discuss later. In contrast, classical consensus protocols require the full and accurate knowledge of $n$ as its safety foundation.
De plus, la famille Snow tolère des incohérences dans la connaissance des participants, comme nous le verrons plus loin. Par contraste, les protocoles de consensus classiques exigent une connaisssance complète et exacte de $n$ comme fondation de la sûreté.

%O Snow's subsampled voting mechanism has two additional properties that improve on previous approaches for consensus. 
Le mécanisme de vote sous-échantillonné possède deux propriété supplémentaires supérieures par rapport aux approches antérieures du consensus.
%O Whereas the safety of quorum-based approaches breaks down immediately when the predetermined threshold $f$ is exceeded,
%O Snow's probabilistic safety guarantee degrades smoothly when Byzantine participants exceed $f$.
Alors que la sûreté des approches basées sur un quorum s'effondre immédiatement quand le seuil prédéterminé $f$ est dépassé,
la garantie de sûreté probabiliste de Snow se dégrade progressivement quand les participants byzantins dépassent $f$.
%O This makes it easier to pick the critical threshold $f$.
Cela facilite le choix du seuil critique $f$.
%O It also exposes new tradeoffs between safety and liveness: the Snow family is more efficient when the fraction of Byzantine nodes is small, and it can be parameterized to tolerate more than a third of the Byzantine
%O nodes by trading off liveness.
Cela expose également de nouveaux compromis entre sûreté et vitalité : la famille Snow est plus efficace quand la fraction de nœuds byzantins est petite, et cela peut être paramétré pour tolérer plus d'un tiers de nœuds byzantins en sacrifiant la vitalité.

%O To demonstrate the potential of this protocol family, we illustrate a practical
%O peer-to-peer payment system, Avalanche. In effect, Avalanche executes multiple Snowball (one from the Snow family) instances with the aid of a Directed Acyclic Graph (DAG). The DAG serves to piggyback multiple instances, reducing the cost from $\Oh{\log{n}}$ to $\Oh{1}$ per node and streamlining the path where there are no conflicting transactions.
Pour démontrer le potentiel de cette famille de protocoles, nous l'illustrons par un système pratique de paiement pair à pair, Avalanche. Dans les faits, Avalanche exécute plusieurs instances de Snowball (l'un des protocoles de la famille Snow) avec l'aide d'un graphe orienté acyclique (\emph{Directed Acyclic Graph} ou DAG). Le DAG sert à empiler plusieurs instances en réduisant le coût de $\Oh{\log{n}}$ à $\Oh{1}$ par nœud et en optimisant le chemin où il n'existe pas de transactions conflictuelles.
%This combination of the best features of traditional and Nakamoto consensus involves one significant tradeoff: liveness for \editchange{equivocating proposals}. %conflicting transactions.
%
%\editchange{Specifically, the consensus protocol from the Snowball family does not guarantee liveness in all cases. It does, however, guarantee logarithmic expected rounds for termination given a propoer initialization heuristic (Section~\ref{sec:liveness}). It also guarantees fast termination when the proposed value is unanimous. As the core part of Avalanche, it guarantees liveness only for \emph{virtuous} transactions, i.e.\ those issued by correct clients and thus guaranteed not to conflict with other transactions.}

%O Overall, the main contribution of this paper is to introduce a brand new family
%O of consensus protocols, based on randomized sampling and metastable decision.
En résumé, la principale contribution de cet article consiste à présenter une nouvelle famille de protocoles de consensus fondés sur un échantillonnage aléatoire et des décisions métastables.
%O The next section provides the model, goals and necessary assumptions for the new protocols.
La section suivante fournit le modèle, les buts et les suppositions nécessaires pour les nouveaux protocoles.
%O Section~\ref{sec:protocol} gives intuition behind the protocols, followed by their full specification,
La section~\ref{sec:protocol} donne l'intuition derrière les protocoles, suivis de leurs spécifications complètes,
%Section~\ref{sec:attack} briefly discusses typical attack vectors and their possible defense,
%O Section~\ref{sec:analysis} provides methodology used
%O by our formal analysis of safety and liveness in Appendix~\ref{sec:full-analysis},
La section~\ref{sec:analysis} fournit la méthodologie employée par notre analyse formelle de sûreté et de vitalité en Appendix~\ref{sec:full-analysis},
%Section~\ref{sec:implementation} describes a Bitcoin-like payment system,  Section~\ref{sec:evaluation} evaluates the system,
%O Section~\ref{sec:implementation} describes Avalanche, a Bitcoin-like payment system,
La section~\ref{sec:implementation} décrit Avalanche, un système de paiement similaire à Bitcoin,
%O Section~\ref{sec:evaluation} evaluates Avalanche,
La section~\ref{sec:evaluation} évalue Avalanche,
%O Section~\ref{sec:related-work} presents related work, and finally, Section~\ref{sec:conclusions} summarizes our contributions.
La section~\ref{sec:related-work} présente les travaux en relation, et, finalement, la section~\ref{sec:conclusions} résume nos contributions.

%O \section{Model and Goals}
\section{Modèle et buts}
\label{sec:model_and_goals}
% \editchange{Because our Snowball family provides strong safety guarantee and liveness guarantee},
% it is possible to build other applications involving large-scale probabilistic consensus. We focus on a cryptocurrency application because of many challenges it poses.
%Nevertheless, Snowball does provide liveness guarantee for conflicting values, so it is possible to extend this single-decree protocol for other possible applications involving large-scale probabilistic consensus.
%\Jon{Are there other applications where this consensus model would be valuable? It's not a BFT RSM, but it would be very intriguing if there were other additional applications.}

%O \tronly{\paragraph{Key Guarantees}}{}
\tronly{\paragraph{Garanties clefs}}{}

% XXXKEVIN NOT CLEAR THIS PARAGRAPH BELOW BELONGS IN THIS SECTION
% \editinsert{In Avalanche}, we adopt what is commonly known as
% Bitcoin's unspent transaction output (UTXO) model.
% In this model,
% \emph{clients} are authenticated and issue cryptographically signed
% transactions that fully consume an existing UTXO and issue new UTXOs.
% Unlike nodes, clients do not participate in the decision process, but only
% supply transactions to the \emph{nodes} running the consensus protocol.
% Two transactions \emph{conflict} if
% they consume the same UTXO and yield different outputs.
% Correct clients never issue conflicting transactions, nor is it possible
% for Byzantine clients to forge conflicts with transactions
% issued by correct clients.
% However, Byzantine clients can issue multiple transactions that conflict
% with one another, and correct clients can only consume one of
% those transactions.
% \editchange{To make use of Snowball consensus in Avalanche}, then, is to \emph{accept} a
% set of non-conflicting transactions in the presence of Byzantine behavior.
% Each client can be considered a replicated state machine whose
% transitions are defined by a totally ordered list of accepted transactions.

%O \paragraph{Safety} Unlike classical consensus protocols, and similar to longest-chain-based consensus protocols such as Nakamoto consensus~\cite{nakamoto2008bitcoin}, we adopt an $\varepsilon$-safety guarantee that is probabilistic. 
\paragraph{Sûreté} À l'inverse des protocoles de consensus classiques, et à l'instar des protocoles de consensus fondés sur la chaîne la plus longue~\cite{nakamoto2008bitcoin}, nous adoptons une garantie de sûreté-$\varepsilon$ qui est probabiliste.
%O In practice, this probabilistic guarantee is as strong as traditional safety guarantees, since appropriately small choices of $\varepsilon$ can render consensus failure negligible, lower than the probability of hardware failure due to random events.
En pratique, cette garantie probabiliste est aussi forte que les garantie de sûreté traditionnelles puisque le choix d'un petit $\varepsilon$ peut rendre la défaillance du consensus négligeable, inférieurs à la probabilité d'une panne matérielle due à des événements imprévisibles.
%OFigure~\ref{fig:fandepsilon} shows how the portion ($f/n$) of misbehaving participants (or computation power) affects the probability of system safety failure (decision of two conflicting proposals), given a choice of finality.
La figure~\ref{fig:fandepsilon} montre comment la portion ($f/n$) de participants (ou de puissance informatique) problématique affecte la probabilité d'une défaillance de la sûreté du système (décision de deux propositions incompatibles), selon un choix de finalité.
% The maximum tolerated Byzantine presence $f$, is dependent on the choice of $\varepsilon$. Similar to Nakamoto consensus, given an observed Byzantine presence $f'$, where $f' \leq f$, the safety failure probability of our protocols maintains the property that $\varepsilon' \leq \varepsilon$. On the other hand, for classical consensus protocols, the failure probability is simply zero for all $f' \leq f$, and almost sure (i.e. one) for $f' > f$.

\begin{figure}[h]
    \includegraphics[width=\linewidth]{figures/safety-f-eps.pdf}
%O    \caption{Classical BFT protocols that tolerate $f$ failures will encounter total safety failure when the threshold is exceeded even by one additional node. The Bitcoin curve shows a typical finality choice for Bitcoin where a block is considered final when it is ``buried'' in a branch having 6 additional blocks compared to any other competing forks. Snowflake belongs to the Snow family, and it is configured with $k=10$, $\beta=150$. Snowflake-7,8 uses $\alpha=7$ and $\alpha=8$ respectively (see Section~\ref{sec:protocol} for the definition of $k$, $\alpha$ and $\beta$.}
    \caption{Les protocoles BFT classiques qui tolèrent $f$ défaillances rencontrent une défaillance totale de leur sûreté quand le seuil est dépaasé même d'un seul nœud supplémentaire. La courbe de Bitcoin montre un choix de finalité typique pour Bitcoin où un bloc est considéré final quand il est \guillemotleft\,enterré\,\guillemotright~ dans une branche sous 6 blocs supplémentaires par rapport aux autres branches concurrentes. Snowflake appartient à la famille Snow et est configuré avec $k=10$, $\beta=150$. Snowflake-7,8 utilise $\alpha=7$ et $\alpha=8$ respectivement (voir en section~\ref{sec:protocol} pour la définition de $k$, $\alpha$ et $\beta$.}
    \label{fig:fandepsilon}
\end{figure}

\tronly{%
\begin{figure}[h]
    \includegraphics[width=\linewidth]{figures/safety-f-eps-log.pdf}
    \caption{Figure~\ref{fig:fandepsilon} Axe des y en log.}
    \label{fig:fandepsilonlog}
\end{figure}
}{}

%O \paragraph{Liveness} All our protocols provide a non-zero probability guarantee of termination within a bounded amount of time. 
\paragraph{Vitalité} Tous nos protocoles fournissent une garantie de probabilité de terminaison dans un laps de temps donné supérieure à zéro.
%O This bounded guarantee is similar to various protocols such as Ben-Or~\cite{ben1983another} and longest-chain protocols.
Cette garantie de limite est similaire à celle de divers protocoles comme Ben-Or~\cite{ben1983another} et les protocoles de chaîne la plus longue.
%O In particular, for Nakamoto consensus, the number of required blocks for a transaction increases exponentially with the number of adversarial nodes, with an asymptote at $f = n/2$ wherein the number is infinite.
En particulier, pour le consensus Nakamoto, le nombre de blocs requis pour une transaction augmente exponentiellement avec le nombre de nœuds antagonistes, avec une asymptote à $f = n/2$ où le nombre est infini. % wut?
%O In other words, the time required for finality approaches $\infty$ as $f$ approaches $n/2$\tronly{ (Figure~\ref{fig:livenessproperties}).}{.}
En d'autres termes, le temps nécessaire à la finalité approche $\infty$ quand $f$ approche $n/2$\tronly{ (Figure~\ref{fig:livenessproperties}).}{.}
%O Furthermore, the required number of rounds is calculable ahead of time, as to allow the system designer to tune liveness at the expense of safety. Lastly, unlike traditional consensus protocols and similar to Nakamoto, our protocols benefit from lower adversarial presence, as discussed in property P3 below.
De plus, le nombre requis de tours est calculable à l'avance, ce qui permet au concepteur du système de régler la vitalité aux dépens de la sûreté. Enfin, contrairement aux protocoles de consensus traditionnels et similairement à Nakamoto, nos protocoles bénéficient d'une moindre présence antagoniste, comme le détaille la propriété P3 ci-dessous.

\tronly{%
\begin{figure}[h!]
    \includegraphics[width=\linewidth]{figures/liveness-f-time.pdf}
%O    \caption{The relation between $f/n$ and the convergence speed, given $\varepsilon = 10^{-20}$. The left figure shows the expected number of blocks to guarantee $\varepsilon$ in Bitcoin, which, counter to commonly accepted folk wisdom, is not a constant $6$, but depends on adversary size to withhold the same $\varepsilon$. The right figure shows the maximum number of rounds required by Snowflake, where being different from Bitcoin, the asymptote is below $0.5$ and varies by the choice of parameters.}
    \caption{Relation entre $f/n$ et la vitesse de convergence pour $\varepsilon = 10^{-20}$. La figure de gauche montre le nombre attendu de blocs pour garantir $\varepsilon$ dans Bitcoin, qui, contrairement à la croyance populaire, n'est pas une constante $6$, mais dépend de la taille de l'adversaire pour maintenir le même $\varepsilon$. La figure de droite montre le nombre maximum de tours requis par Snowflake où, étant différent de Bitcoin, l'asymptote se trouve sous $0.5$ et varie selon les paramètres.}
    \label{fig:livenessproperties}
\end{figure}
}

%O \emph{Formal Guarantees}: Let the system be parameterized for an $\varepsilon$ safety failure probability under a maximum expected $f$ number of adversarial nodes. Let $\Oh{\log n} < t_{max} < \infty$ be the upper bound of the execution of the protocols. The Snow protocols then provide the following guarantees:
\emph{Garantie formelle} : Soit un paramétrage du système pour une probabilité de défaillance de la sûreté $\varepsilon$ pour un nombre maximal attendu $f$ de nœuds antagonistes. Soit $\Oh{\log n} < t_{max} < \infty$ la limite supérieure de l'exécution du protocole. Les protocoles Snow fournissent alors les garanties suivantes\,:
\begin{compactitem}
% RVR: this property is unnecessary because the liveness property already ensures non-triviality
%    \item \textbf{Non-triviality}: To ensure that the protocol carries out real work, decisions must include values proposed by external clients;

%O     \item \textbf{P1. Safety.} When decisions are made by any two correct nodes, they decide on conflicting transactions with negligible probability ($\leq \varepsilon$).
     \item \textbf{P1. Sûreté.} Quand les décisions sont prises par deux nœuds corrects, ils décident de transactions conflictuelles avec une probabilité négligeable ($\leq \varepsilon$).
    % \item \textbf{P2. Liveness.} Transactions will be accepted by every correct node in $\Oh{\log n}$ rounds if either the observed Byzantine presence $f'$, where $f' < f$, is sufficiently small, or the network is initialized in a univalent state.
%O     \item \textbf{P2. Liveness (Upper Bound).} Snow protocols terminate with a strictly positive probability within $t_{max}$ rounds.  
     \item \textbf{P2. Vitalité (limite supérieure).} Les protocoles Snow se terminent avec une probabilité strictement positive en au plus $t_{max}$ tours.
%O     \item \textbf{P3. Liveness (Strong Form).} If $f \leq \Oh{\sqrt{n}}$, then the Snow protocols terminate with high probability ($\geq 1 - \varepsilon$) in $\Oh{\log{n}}$ rounds. 
     \item \textbf{P3. Vitalité (forme forte).} Si $f \leq \Oh{\sqrt{n}}$, alors les protocoles Snow se terminent avec une forte probabilité ($\geq 1 - \varepsilon$) en $\Oh{\log{n}}$ tours.
\end{compactitem}
% Instead of unconditional agreement, our approach guarantees that safety will be upheld with probability $1-\varepsilon$, where the choice of the security parameter $\varepsilon$ is under the control of the system designer and applications.

%O \paragraph{Network} 
\paragraph{Réseau} 
%O In the standard definition of asynchrony~\cite{ben1983another}, message transmission time is finite, but the distribution is unspecified (and thus the delivery time can be unbounded for some messages). This implies that the scheduling of message transmission itself could behave arbitrarily, and potentially even maliciously (with full asynchrony).
Dans la définition standard de l'asynchronie~\cite{ben1983another}, le temps de transmission des messages est fini, mais la distribution n'est pas spécifiée (donc le temps de délivrance peut être sans limite pour certains messages). Cela implique que l'échelonnement de la transmission des messages lui-même peut être quelconque, voire potentiellement malveillant (pour une complète asynchronie).
%O We use a modified version of this model, which is well-accepted~\cite{banerjee2014epidemic, ganesh2005effect, draief2006thresholds, keeling2011modeling, liggett1997stochastic} in the analysis of epidemic networks and gossip-based stochastic systems. In particular, we fix the distribution of message delay to that of the exponential distribution.
Nous employons une version modifiée de ce modèle, lequel est bien accepté~\cite{banerjee2014epidemic, ganesh2005effect, draief2006thresholds, keeling2011modeling, liggett1997stochastic} dans l'analyse des réseaux épidémiques et des systèmes stochastiques à base de \emph{gossip}. En particulier, nous fixons la distribution des délais de messages à celle de la distribution exponentielle.
%O We note that, just like in the standard asynchronous model, there is a strictly non-zero probability that any correct node may execute its next local round only after an arbitrarily large amount of time has passed.
Nous notons que, tout comme dans le modèle asynchrone standard, il existe une probabilité strictement non-nulle que tout nœud correct ne peut exécuter son prochain tour local qu'après qu'un laps de temps arbitrairement long a passé.
%O Furthermore, we also note that scheduling only applies to correct nodes, and the adversary may execute arbitrarily, as discussed later. 
De plus, nous notons également que l'échelonnement ne s'applique qu'aux nœuds corrects, et que l'adversaire peut s'exécuter arbitrairement, comme nous le verrons plus loin.

%O \paragraph{Achieving Liveness}
\paragraph{Obtention de la vitalité} % HOULA
%O Classical consensus that works with asynchrony does not get stuck in a single phase of voting because the vote initiator always polls votes from all known participants and waits for $n - f$ responses.
Les consensus classiques qui fonctionnent en asynchronie ne restent pas bloqués lors d'une phase de vote car l'initiateur du vote interroge toujours tous les participants connus et attend $n - f$ réponses.
%The consequence of these two assumptions is therefore that progress cannot be indefinitely delayed by the adversary since the correct nodes (whose number is sufficient for voting) will eventually deliver the required messages.
%O In our system, however, nodes operate via subsampling, hence it is possible for a single sample to select a majority of adversarial nodes, and therefore the node gets stuck waiting for the responses. To ensure liveness, a node should be able to wait with some timeout. Therefore, our protocols are synchronous in order to guarantee liveness. Lastly, it is worth noting that Nakamoto consensus is synchronous, in which the required difficulty of proof-of-work is dependent on the maximum network delay~\cite{PassSS17}. %Also, other protocols that rely on gossip [Citation here] are also essentially synchronous due to the synchronous nature of gossip protocols. \editinsert{RvR pointed this out, we need to carefully word it though.
Dans notre système, cependant, les nœuds opèrent par sous-échantillonnage, d'où la possibilité pour un seul échantillon qu'une majorité de nœuds antagonistes soit sélectionné, ce qui contraint le nœud à attendre en vain une réponse. Pour s'assurer de la vitalité, un nœud doit pouvoir poser une limite à l'attente. Enfin, il faut noter que le consensus Nakamoto est synchrone et que la difficulté requise pour la preuve de travail dépend du délai maximum du réseau~\cite{PassSS17}. 

%O \paragraph{Adversary}
\paragraph{Adversité} % HOULA : Adversaire ? Adversaires ? Adversatif ?
%O The adversarial nodes execute under their own internal scheduler, which is unbounded in speed, meaning that all adversarial nodes can execute at any infinitesimally small point in time, unlike correct nodes. 
Les nœuds antagonistes s'exécutent avec un ordonnanceur interne qui leur est propre, non limité en vitesse, ce qui signifie que tout nœud antagoniste peut s'exécuter à un moment précis infiniment petit, au contraire des nœuds corrects.
%O The adversary can view the state of every honest node at all times and can instantly modify the state of all adversarial nodes. 
L'adversaire peut voir l'état de chaque nœud honnête à tout moment et peut instantanément modifier l'état de tout nœud antagoniste.
%O It cannot, however, schedule or modify communication between correct nodes.
Il ne peut, cependant, ordonnancer ou modifier la communication entre les nœuds corrects.
%O Finally, we make zero assumptions about the behavior of the adversary, meaning that it can choose any execution strategy of its liking.
Enfin, nous ne faisons aucune hypothèse sur le comportement de l'adversaire, ce qui signifie qu'il peut choisir la stratégie d'exécution qui lui convient.
%O In short, the adversary is computationally bounded (it cannot forge digital signatures) but otherwise is point-to-point informationally unbounded (knows all state) and round-adaptive (can modify its strategy at any time). 
En résumé, l'adversaire est limité en puissance informatique (il ne peut pas forger des signatures numériques) mais, hormis cela, il n'est pas limité en matière informationnelle (il connaît tout de l'état) et il est adaptatif en matière de tours (il peut modifier sa stratégie à tout moment).

\paragraph{Attaques Sybil}
%O Consensus protocols provide their guarantees based on assumptions that only a fraction of participants are adversarial.
Les protocoles de consensus fournissent leurs garanties fondées sur la supposition que seule une fraction des participants sont malveillants.
%O These bounds could be violated if the network is naively left open to arbitrary participants.
Ces limites peuvent être violées si le réseau est naïvement laissé ouvert à des participants quelconques.
%O In particular, a Sybil attack~\cite{douceur2002sybil}, wherein a large number of identities are generated by an adversary, could be used to exceed the bounds.
En particulier, une attaque Sybil~\cite{douceur2002sybil}, où un grand nombre d'identités sont générées par un adversaire, peut être employée pour dépasser ces limites.

%O A long line of work, including PBFT~\cite{castro1999practical}, treats the Sybil problem separately from consensus, and rightfully so, as Sybil control mechanisms are distinct from the underlying, more complex agreement protocol\footnote{This is not to imply that every consensus protocol can be coupled/decoupled with every Sybil control mechanism.}.
Une longue suite de travaux, comme PBFT~\cite{castro1999practical}, sépare le problème de Sybil de celui du consensus, à juste titre puisque les mécanismes de contrôle de Sybil sont distincts du protocole d'accord plus complexe sous-jacent\footnote{Cela n'implique pas que tout protocole de consensus puisse être couplé/découplé de tout mécanisme de contrôle de Sybil}.
%O In fact, to our knowledge, only Nakamoto-style consensus has ``baked-in'' Sybil prevention as part of its consensus, made possible by chained proof-of-work~\cite{aspnes2005exposing}, which requires miners to continuously stake a hardware investment.
En fait, à notre connaissance, le consensus Nakamoto est le seul à avoir intégré la protection anti-Sybil dans son consensus, chose rendue possible par la preuve de travail chaînée~\cite{aspnes2005exposing} qui demande aux mineurs de continuellement mettre en jeu un investissement matériel.
%O Other protocols, discussed in Section~\ref{sec:related-work}, rely on proof-of-stake (by economic argument) or proof-of-authority (by administrative argument that makes the system ``permissioned'').
D'autres protocoles, dont il est question en section~\ref{sec:related-work}, se basent sur la preuve d'enjeu (\emph{proof of stake} ou PoS, par un argument économique) ou preuve d'autorité (\emph{proof of authority} ou PoA, par un argument administratif) qui rend le système \guillemotleft\,permissionné\,\guillemotright.
%O The consensus protocols presented in this paper can adopt any
%O Sybil control mechanism, although proof-of-stake is most aligned with their quiescent operation.
Les protocoles de consensus présentés dans cet article peuvent adopter n'importe quel mécanisme de contrôle de Sybil, bien que la preuve d'enjeu soit la plus en ligne avec le caractère économe de leur opération.
%O One can use an already established proof-of-stake based mechanism~\cite{GiladHMVZ17}.
On peut utiliser un mécanisme en preuve d'enjeu déjà établi.
%O The full deployment of an autonomous P2P payment system incorporating staking mechanism is beyond the scope of this paper, whose focus is on a novel design paradigm of the core consensus algorithm.
Le déploiement complet d'un système de paiement autonome en P2P incorporant des mécanismes d'enjeu dépasse le cadre de cet article, dont l'objet est un nouveau paradigme de conception de l'algorithme de consensus.

% Sybil control mechanisms are orthogonal and separate from the consensus protocols. All such protocols, excluding Nakamoto-style consensus protocols, require a mechanism for network identity establishment. In a real implementation of Avalanche, the Sybil problem would be solved through a staking mechanism. 

%O \paragraph{Flooding Attacks}
\paragraph{Attaques par inondation}
%O Flooding/spam attacks are a problem for any distributed system. 
Les attaques par inondation (\emph{flooding}) et spam représentent un problème pour tout système distribué.
%O Without a protection mechanism, an attacker can generate large numbers of transactions and flood protocol data structures, consuming storage.
Sans mécanisme de protection, un attaquant peut générer un grand nombre de transactions et inonder les structures de données du protocole, consommant ainsi des ressources de stockage.
% Although there is no proper, protocol-level methodology to prevent such an attack, there are very effective heuristics that we can employ.
%O There are a multitude of techniques to deter such attacks, including network-layer protection, proof-of-authority, local proof-of-work and economic mechanisms. 
Il existe une multitude de techniques pour repousser ces attaques comme la protection de la couche réseau, la preuve d'autorité, la preuve de travail local et des mécanismes économiques.
%O In Avalanche, we use transaction fees, making such attacks costly even if the attacker is sending money back to addresses under its control.
Dans Avalanche, nous utilisons les frais de transaction, rendant ainsi ces attaques coûteuses même si l'attaquant renvoie l'argent aux adresses qu'il contrôle.



%O \paragraph{Additional Assumptions}
\paragraph{Hypothèses supplémentaires}
%O We do not assume that all members of the network are known to all participants, but rather may temporarily have some discrepancies in network view.
Nous ne supposons pas que tous les membres du réseau sont connus de tous les participants, car la vue du réseau qu'ont ces derniers peut souffrir d'incohérences temporaires.
%O We quantify the bounds on the discrepancy in Appendix~\ref{sec:full-analysis-churn}.
Nous quantifions les limites en Annexe~\ref{sec:full-analysis-churn}.
%O We assume a safe bootstrapping mechanism, similar to that of Bitcoin, that enables a node to connect with sufficiently many correct nodes to acquire a statistically unbiased view of the network.
Nous supposons un mécanisme de démarrage initial sûr, similaire à celui de Bitcoin, qui permet à un nœud de se connecter à suffisamment de nœuds corrects pour acquérir une vue statistiquement non biaisée du réseau.
%O We do not assume a PKI\@.
Nous ne prévoyons pas une PKI\@.
%O Finally, we make standard cryptographic assumptions related to digital signatures and hash functions.
Enfin, nous nous reposons sur les hypothèses standard en matière de cryptographie dans le domaine des signatures numériques et des fonctions de hachage.
%\editinsert{TODO: Talk about synchrony assumption, and justify it by mentioning Bitcoin.}
%\editinsert{TODO: Talk about we don't address Sybil attack, and justify it by mentioning Algorand (we also use Algorand as a comparison in Evaluation, so it will totally make sense here.}


\section{Conception du Protocole}\label{sec:protocol}
Nous partons d'un protocole non résistant au problème des généraux byzantins appelé Slush, en amenant
progressivement Snowflake et Snowball, tous basés sur le même mécanisme métastable de vote basé sur une majorité.
Ces derniers sont des protocoles de consensus à simple décret présentant plusieurs niveaux de robustesse. Nous
détaillons les caractéristiques complètes de ces protocoles dans cette section, suivie de leur analyse en section
suivante, les preuves formelles étant disponibles en annexe.

%O \section{Protocol Design}\label{sec:protocol}
%O We start with a non-BFT protocol called Slush and progressively build up to Snowflake and Snowball, all based on the same common majority-based metastable voting mechanism.
%O These protocols are single-decree consensus protocols of increasing robustness.
%O We provide full specifications for the protocols in this section, and defer the analysis to the next section, and present formal proofs in the appendix.

%0 \subsection{Slush: Introducing Metastability}
\subsection{Slush: A propos de métastabililté}

%O The core of our approach is a single-decree consensus protocol,
%O inspired by epidemic or gossip protocols.
%O The simplest protocol, Slush, is the foundation of this family, shown in Figure~\ref{fig:slush-loop}.
%O Slush is \emph{not} tolerant to Byzantine faults, only crash-faults (CFT), but serves as an illustration for the BFT protocols that follow.
%O For ease of exposition, we will describe the operation of Slush using a decision between two conflicting colors, red and blue.

Le principe de notre approche est un protocole de consensus à décision simple inspiré des protocoles dits "épidémiques"
ou "gossip". Le protocole le plus simple, Slush, est la fondation de cette famille, comme le montre la
Figure~\ref{fig:slush-loop}. Slush \emph{n'est pas} tolérant aux fautes byzantines, seulement aux fautes par défaut
de fonctionnement (CFT), mais sert à mettre en avant les autres protocoles tolérants aux fautes byzantines qui vont
suivre. Dans un souci de simplicité de présentation, nous décrirons le fonctionnement de Slush en le comparant
à une décision à prendre entre deux couleurs incompatibles, le rouge et le bleu.

%O In Slush, a node starts out initially in an uncolored state.
%O Upon receiving a transaction from a client, an uncolored node updates its own color to the one carried in the transaction and initiates a query.
%O To perform a query, a node picks a small, constant sized ($k$) sample of the network uniformly at random, and sends a query message.
%O Upon receiving a query, an uncolored node adopts the color in the query, responds with that color, and initiates its own query, whereas a colored node simply responds with its current color.
%O Once the querying node collects $k$ responses, it checks if a fraction $\ge\alpha$ are for the same color, where $\alpha > \floor{k/2}$ is a protocol parameter.
%O If the $\alpha$ threshold is met and the sampled color differs from the node's own color, the node flips to that color.
%O It then goes back to the query step, and initiates a subsequent round of query, for a total of $m$ rounds.
%O Finally, the node decides the color it ended up with at time $m$.

Avec Slush, un noeud démarre dans un état de couleur neutre. Après réception d'une transaction envoyée par un client,
un node de couleur neutre adopte la couleur définie dans la transaction et initie une requête. Pour lancer une
requête, le noeud choisit un échantillon réduit et de taille constante ($k$) de noeuds appartenant au réseau suivant
une distribution uniformément aléatoire puis initie sa propre requête, tandis qu'un noeud déja coloré répond
simplement avec sa couleur actuelle. Une fois que le noeud qui fait la requête récupère $k$ réponses, il vérifie si
une proportion $\ge\alpha$ de l'échantillon retourne la même couleur, $\alpha > \floor{k/2}$ étant un paramètre
du protocole. Si le seuil $\alpha$ est dépassé et que la couleur dominante revenant de l'échantillon sollicité est
différente de la couleur propre du node à l'origine de la requête, ce node adopte cette nouvelle couleur. Il revient
ensuite à l'étape de génération de la requête et lance un nouveau tour de requête jusqu'à un total de $m$ tours.
En définitive, le node décide de sa couleur finale à l'instant $m$.

\algnewcommand{\IIf}[1]{\State\algorithmicif\ #1\ \algorithmicthen}
\algnewcommand{\EndIIf}{\unskip\ \algorithmicend\ \algorithmicif}

\newcommand{\codecolor}{\mathit{col}}
\newcommand{\codecount}{\mathit{cnt}}
\newcommand{\codelastcol}{\mathit{lastcol}}
\newcommand{\assign}{\coloneqq}
\begin{figure}
    \small
\begin{algorithmic}[1]
    \Procedure{onQuery}{$v, \codecolor'$}
        \IIf{$\codecolor = \bot$} $\codecolor \assign \codecolor'$
        \State\Call{répondre}{$v, \codecolor$}
    \EndProcedure
    \Procedure{slushLoop}{$u, \codecolor_0 \in \{\texttt{R}, \texttt{B}, \bot\}$}
        \State $\codecolor \assign \codecolor_0$ \textrm{// initialise avec une couleur}
        \For{$r \in \{1\ldots m\}$}
            \State \textrm{// Si $\bot$, réitère jusqu'à ce que \textsc{onQuery} applique la couleur}
            \If{$\codecolor = \bot$}
                \Continue
            \EndIf
            \State \textrm{// échantillonne aléatoirement parmi les noeuds connus}
            \State $\mathcal{K} \assign \Call{échantillon}{\mathcal{N}\backslash u, k}$
            \State $P \assign \texttt{[}\Call{requête}{v, \codecolor}\quad\textbf{pour}\ v \in \mathcal{K}\texttt{]}$
            \For{$\codecolor' \in \{\texttt{R}, \texttt{B}\}$}
                \If{$P.\Call{nombre}{\codecolor'} \ge \alpha$}
                    \State $\codecolor \assign \codecolor'$
                \EndIf
            \EndFor
        \EndFor
        \State \Call{accepte}{$\codecolor$}
    \EndProcedure
    \captionof{figure}{Protocole Slush. Les temps d'expiration sont omis dans un souci de lisibilité.}\label{fig:slush-loop}
\end{algorithmic}
\end{figure}

%O Slush has a few properties of interest.
%O First, it is almost \emph{memoryless}: a node retains no state between rounds other than its current color, and in particular maintains no history of interactions with other peers.
%O Second, unlike traditional consensus protocols that query every participant, every round involves sampling just a small, constant-sized slice of the network at random.
%O Third, Slush makes progress under any network configuration (even fully bivalent state, i.e. 50/50 split between colors), since random perturbations in sampling will cause one color to gain a slight edge and repeated samplings afterwards will build upon and amplify that imbalance.
%O Finally, if $m$ is chosen high enough, Slush ensures that all nodes will be colored identically with high probability (whp).
%O Each node has a constant, predictable communication overhead per round, and $m$ grows logarithmically with $n$.

Slush a quelques propriétés intéréssantes. Premièrement, il n'a quasiment \emph{pas besoin de mémoire}: un noeud ne
stocke aucun état intermédiaire entre chaque tour autre que sa couleur actuelle, et plus particulièrement ne stocke
aucun historique de ses interactions avec les autres noeuds. Deuxièmement, contrairement aux protocoles de consensus
traditionnels qui sollicitent tous les participants, chaque tour n'implique qu'un échantillon du réseau réduit et de
taille constante choisi aléatoirement. Troisièmement, Slush progresse quelque soit la configuration du réseau (même
depuis un état entièrement bivalent, ex: partage 50/50 entre les deux couleurs) vu que des perturbations aléatoires
sur l'échantillonnage auront pour conséquence de fournir un léger avantage à l'une des deux couleurs qui sera ensuite
amplifié au fur et à mesure des échantillonnages.
Finalement si $m$ est choisi pour être suffisamment élevé, Slush s'assure que tous les noeuds convergeront vers la
même couleur avec une haute probabilité. Chaque noeud nécéssite un temps de communication par tour constant et
prévisible, et $m$ croît de manière logarithmique suivant $n$.

\tronly{
%O The Slush protocol does not provide a strong safety guarantee in the presence of Byzantine nodes.
%O In particular, if the correct nodes develop a preference for one color, a Byzantine adversary can attempt to flip nodes
%O to the opposite so as to keep the network in balance, preventing a decision.
%O We address this in our first BFT protocol that introduces more state storage at the nodes.

Le protocole Slush ne fournit pas de fortes garanties quant à la sûreté de fonctionnement en la présence de noeuds
byzantins. En particulier si les noeuds légitimes développent une préférence pour une certaine couleur, un adversaire
byzantin pourra inverser la couleur des noeuds afin de maintenir le système à l'équilibre, incapable de prendre une
décision. Nous adressons ce problème dans notre premier protocole tolérant aux fautes byzantines qui introduit un
meilleur suivi de l'état au niveau des nodes.
}{
%O We next examine how to extend Slush to tolerate Byzantine behavior.
Nous examinons ensuite comment améliorer Slush pour être tolérant au problème des généraux byzantins.
}

\subsection{Snowflake: BFT}

Snowflake améliore Slush en ajoutant un compteur unique qui capture la force de conviction d'un noeud dans sa couleur
actuelle. Ce compteur associé à chaque noeud stocke le nombre d'échantillons du réseau consécutifs que le noeud a
sollicité et qui ont retourné la même couleur. Un noeud accepte sa couleur actuelle lorsque son compteur atteint $\beta$,
un autre paramètre de sécurité. La Figure~\ref{fig:snowflake-loop} montre le protocole amélioré qui inclue les
modifications suivantes:

%O Snowflake augments Slush with a single counter that captures the strength of a node's conviction in its current color.
%O This per-node counter stores how many consecutive samples of the network by that node have all yielded the same color.
%O A node accepts the current color when its counter reaches $\beta$, another security parameter.
%O Figure~\ref{fig:snowflake-loop} shows the amended protocol, which includes
%O the following modifications:

\begin{compactenum}
	\item Chaque node maintient un compteur $\mathit{cnt}$;
    \item A chaque changement de couleur, le compteur $\mathit{cnt}$ se réinitialise à 0;
    \item Après chaque requête réussie qui retourne $\ge \alpha$ réponses en faveur de la même couleur que le noeud,
      ce dernier incrémente $\mathit{cnt}$.
\end{compactenum}

%O \begin{compactenum}
%O 	\item Each node maintains a counter $\mathit{cnt}$;
%O     \item Upon every color change, the node resets $\mathit{cnt}$ to 0;
%O     \item Upon every successful query that yields $\ge \alpha$ responses for the same color as the node, the node increments $\mathit{cnt}$.
%O \end{compactenum}

\newcommand{\codemaj}{\mathit{maj}}
\newcommand{\codefalse}{\texttt{false}}
\newcommand{\codetrue}{\texttt{true}}
\begin{figure}
    \small
\begin{algorithmic}[1]
    \Procedure{snowflakeLoop}{$u, \codecolor_0 \in \{\texttt{R}, \texttt{B}, \bot\}$}
        \State $\codecolor \assign \codecolor_0$, $\codecount \assign 0$
        \While{\textrm{undecided}}
            \If{$\codecolor = \bot$}
                \Continue
            \EndIf
            \State $\mathcal{K} \assign \Call{sample}{\mathcal{N}\backslash u, k}$
            \State $P \assign \texttt{[}\Call{query}{v, \codecolor}\quad\textbf{for}\ v \in \mathcal{K}\texttt{]}$
            \State $\codemaj \assign \codefalse$
            \For{$\codecolor' \in \{\texttt{R}, \texttt{B}\}$}
            \If{$P.\Call{count}{\codecolor'} \ge \alpha$}
                \State $\codemaj \assign \codetrue$
                \If{$\codecolor' \neq \codecolor$}
                    \State $\codecolor \assign \codecolor'$, $\codecount \assign 1$
                \Else\hspace{1ex}$\codecount\texttt{++}$
                \EndIf
                \IIf {$\codecount \ge \beta$} \Call{accept}{$\codecolor'$}
            \EndIf
            \EndFor
            \IIf{$\codemaj = \codefalse$} $\codecount \assign 0$
        \EndWhile
    \EndProcedure
    \captionof{figure}{Snowflake.}\label{fig:snowflake-loop}
\end{algorithmic}
\end{figure}

\begin{figure}[t]
    \small
\begin{algorithmic}[1]
    \Procedure{snowballLoop}{$u, \codecolor_0 \in \{\texttt{R}, \texttt{B}, \bot\}$}
        \State $\codecolor \assign \codecolor_0$, $\codelastcol \assign \codecolor_0$, $\codecount \assign 0$
        \State $d[\texttt{R}] \assign 0$, $d[\texttt{B}] \assign 0$
        \While{\textrm{undecided}}
            \IIf{$\codecolor = \bot$} \Continue
            \State $\mathcal{K} \assign \Call{sample}{\mathcal{N}\backslash u, k}$
            \State $P \assign \texttt{[}\Call{query}{v, \codecolor}\quad\textbf{for}\ v \in \mathcal{K}\texttt{]}$
            \State $\codemaj \assign \codefalse$
            \For{$\codecolor' \in \{\texttt{R}, \texttt{B}\}$}
            \If{$P.\Call{count}{\codecolor'} \ge \alpha$}
                \State $\codemaj \assign \codetrue$
                \State $d[\codecolor']\texttt{++}$
                \If {$d[\codecolor'] > d[\codecolor]$}
                        \State$\codecolor \assign \codecolor'$
                \EndIf
                \If{$\codecolor' \neq \codelastcol$}
                    \State$\codelastcol \assign \codecolor'$, $\codecount \assign 1$
                \Else\hspace{1ex}$\codecount\texttt{++}$
                \EndIf
                \IIf {$\codecount \ge \beta$} \Call{accept}{$\codecolor'$}
            \EndIf
            \EndFor
            \IIf{$\codemaj = \codefalse$} $\codecount \assign 0$
        \EndWhile
    \EndProcedure
    \captionof{figure}{Snowball.}\label{fig:snowball-loop}
\end{algorithmic}
\end{figure}

Quand le protocole est correctement parametré pour un seuil donné de noeuds byzantins et un niveau de garantie
$\varepsilon$, il peut garantir à la fois la sécurité de fonctionnement (P1) et la vitalité (P2, P3).
Comme nous le démontrons plus loin, il existe un état irréversible à partir duquel une décision est inévitable. Les noeuds
légitimes commencent à se positionner après cet état irréversible et adoptent la même couleur. Une intuition
supplémentaire, que nous ne détaillons pas dans ce papier, introduit l'existence d'un point de changement de phase à
partir duquel les nodes byzantins perdent toute capacité à maintenir le réseau dans un état bivalent.

%O When the protocol is correctly parameterized for a given threshold of Byzantine nodes and a desired $\varepsilon$-guarantee, it can ensure both safety (P1) and liveness (P2, P3).
%O As we later show, there exists an irreversible state after which a decision is inevitable. Correct nodes begin to commit past the irreversible state to adopt the same color, whp. For additional intuition, which we do not expand in this paper, there also exists a phase-shift point, where the Byzantine nodes lose ability to keep network in a bivalent state.

%O \subsection{Snowball: Adding Confidence}

\subsection{Snowball: Introduire la notion de confiance}

La notion d'état de Snowflake est éphémère: le compteur est réinitialisé à chaque changement de couleur.
Snowball améliore Snowflake avec des \emph{compteurs de confiance} qui capturent le nombre de requêtes ayant retourné
un résultat en faveur de la couleur du noeud au dessus d'un certain seuil (Figure ~\ref{fig:snowball-loop}).
Un node prend une décision s'il obtient $\beta$ réponses consécutives en faveur d'une couleur. Cependant il change
sa préférence uniquement sur la base de la confiance totale accumulée. Les différences entre Snowflake et Snowball
sont:

\begin{compactenum}
    \item Après chaque requête réussie, le noeud incrémente son compteur de confiance associé à la couleur retournée.
    \item Un noeud change de couleur quand la confiance associée à sa couleur actuelle devient inférieure à la
      valeur de la confiance associée à  la nouvelle couleur.
\end{compactenum}

%O Snowflake's notion of state is ephemeral: the counter gets reset with every color flip.
%O Snowball augments Snowflake with \emph{confidence counters} that capture the number of queries that have yielded a threshold result for their corresponding color (Figure ~\ref{fig:snowball-loop}).
%O A node decides if it gets $\beta$ consecutive chits for a color. However, it only changes preference based on the total accrued confidence.
%O The differences between Snowflake and Snowball are as follows:
%O \begin{compactenum}
%O     \item Upon every successful query, the node increments its confidence counter for that color.
%O     \item A node switches colors when the confidence in its current color becomes lower than the confidence value of the new color.
%O \end{compactenum}


\section{Analyse}
\label{sec:analysis}
Pour des raisons de manque de place, nous déplaçons certains détails importants vers l'Annexe~\ref{sec:full-analysis},
dans laquelle nous démontrons que sous certaines hypothèses distinctes et indépendantes, la famille de protocoles de
consensus Snow possède des propriétés de sûreté de fonctionnement (P1) et de vitalité (P2, P3). Dans cette section,
nous résumons nos résultats principaux en fournissant des ébauches de preuves.

%O \section{Analysis}
%O \label{sec:analysis}
%O Due to space limits, we move some core details to Appendix~\ref{sec:full-analysis}, where we show that under certain independent and distinct assumptions, the Snow family of consensus protocols provide safety (P1) and liveness (P2, P3) properties.
%O In this section, we summarize our core results and provide some proof sketches.

\paragraph{Notation} En considérant que le réseau consiste d'un ensemble de $n$ noeuds (représentés par l'ensemble
$\mathcal{N}$), où $c$ sont des noeuds légitimes (représentés par l'ensemble $\mathcal{C}$) et $f$ sont les noeuds
byzantins (représentés par l'ensemble $\mathcal{B}$). Soient $u, v \in \mathcal{C}$ des références à deux noeuds
légitimes pris au hasard dans le réseau. Soient $k, \alpha, \beta \in \mathbb{Z}^+$ des entiers positifs où
$\alpha > \floor{k/2}$. A partir de maintenant, $k$ fera toujours référence à la taille des déchantillons du réseau,
où $k \leq n$, et $\alpha$ sera le seuil de majorité requis pour considérer l'expérience de vote comme ``réussie''.
En général, nous définissons $\mathcal{S}$ comme étant l'état (ou la configuration) du réseau à tout moment.

%O \paragraph{Notation} Let the network consist of a set of $n$ nodes (represented by set $\mathcal{N}$), where $c$ are correct nodes (represented by set $\mathcal{C}$) and $f$ are Byzantine nodes (represented by set $\mathcal{B}$).
%O Let $u, v \in \mathcal{C}$ refer to any two correct nodes in the network. Let $k, \alpha, \beta \in \mathbb{Z}^+$ be positive integers where $\alpha > \floor{k/2}$. From now on, $k$ will always refer to the network sample size, where $k \leq n$, and $\alpha$ will be the majority threshold required to consider the voting experiment a ``success''. In general, we will refer to $\mathcal{S}$ as the state (or configuration) of the network at any given time.
%O

\paragraph{Framework de modélisation} Afin de modéliser nos protocoles de manière formelle, nous utilisons des
processus Markov à temps continu (CTMC). L'espace contenant les états est dénombrable (et fini), et les transitions
entre états s'opèrent sur un espace de temps continu. Les CTMCs proposent une modélisation naturelle de nos protocoles
sachant que les transitions entre états ne se font pas par étapes et en marche ordonnée pour chaque noeud (à la fin de
chaque unité de temps) mais arrivent plutôt à n'importe quel moment et indépendamment des autres noeuds.

Nous nous concentrons sur un consensus binaire, même si les résultats en term de sûreté de fonctionnement se
généralisent sur plus de deux valeurs. Nous pouvons imaginer le réseau comme un ensemble de noeuds colorés soit en
rouge soit en bleu, et nous ferons référence à cette configuration à l'instant $t$ comme étant $\mathcal{S}_t$.
Nous modélisons nos protocoles à travers un processus à temps continu contenant deux états, dans lequel tous les noeuds
sont rouges ou tous les noeuds sont bleus. L'espace $\mathcal{S}$ des états du processus stochastique est une version
condensée de l'espace de configuration complet, où chaque état $\{0, \dots, n\}$ représente le nombre total de noeuds
bleus dans le système.

La simplification qui nous permet d'analyser ce système consiste à s'affranchir du besoin de garder un historique de
tous les chemins d'exécution, ainsi que toutes les stratégies d'attaque possibles, et de se concentrer plutôt
entièrement sur un unique état, sans considérer la manière d'arriver à cet état. Plus spécifiquement, l'idée principale
à retenir de notre analyse est l'identification d'un état \textit{d'irréversibilité} du système, cet état à partir
duquel un tel nombre de noeuds légitimes a adopté soit la couleur rouge soit la couleur bleue que la possibilité de
revenir à la couleur minoritaire est très peu probable.

%O \paragraph{Modelling Framework} To formally model our protocols, we use continuous-time Markov processes (CTMC).
%O The state space is enumerable (and finite), and state transitions occur in continuous time.
%O CTMCs naturally model our protocols since state transitions do not occur in epochs and in lockstep for every node (at the end of every time unit) but rather occur at any time and independently of each other.

%O We focus on binary consensus, although the safety results generalize to more than two values. We can think of the network as a set of nodes either colored red or blue, and we will refer to this configuration at time $t$ as $\mathcal{S}_t$.
%O We model our protocols through a continuous-time process with two absorbing states, where either all nodes are red or all nodes are blue.
%O The state space $\mathcal{S}$ of the stochastic process is a condensed version of the full configuration space, where each state $\{0, \dots, n\}$ represents the total number of blue nodes in the system.

%O The simplification that allows us to analyze this system is to obviate the need to keep track of all of the execution paths, as well as all possible adversarial strategies, and rather focus entirely on a single state of interest, without regards to how we achieve this state.
%O More specifically, the core extractable insight of our analysis is in identifying the \textit{irreversibility} state of the system, the state upon which so many correct nodes have usurped either red or blue that reverting back to the minority color is highly unlikely.

\subsection{Sûreté de fonctionnement}

%O \subsection{Safety}

\paragraph{Slush}
En partant du principe que tous les noeuds partagent le même $\mathcal{N}$, et en Annexe~\ref{sec:full-analysis-churn},
nous expliquons comment relâcher le besoin pour les noeuds d'avoir connaissance de leur appartenance. Nous modélisons
les dynamiques du système à travers un processus à temps continu contenant deux états, tous les noeuds rouges ou tous
les noeuds bleus. Prenons $\{X_{t \geq 0}\}$ la variable aléatoire qui décrit l'état du système à l'instant $t$, où
$X_0 \in \{0, \dots, c\}$.
Nous commençons par détailler le résultat le plus important des dynamiques de sûreté de fonctionnement de notre
processus: les probabilités de \emph{réversibilité} du processus \textbf{Slush}. Tous les autres résultats formels de
ce papier sont, en simplifiant, des dérivations et améliorations intuitives de ce résultat.

%0 \paragraph{Slush}
%0 We assume that
%0 %$\mathcal{L}(u) = \mathcal{N}$ for all $u \in \mathcal{N}$.
%0 all nodes share the same $\mathcal{N}$, and in
%0 Appendix~\ref{sec:full-analysis-churn}, we sketch how to relax the requirement of the membership knowledge.
%0 We model the dynamics of the system through a continuous-time process where two states are absorbing, namely the all-red or all-blue state. Let $\{X_{t \geq 0}\}$ be the random variable that describes the state of the system at time $t$, where $X_0 \in \{0, \dots, c\}$.
%0 We begin by immediately discussing the most important result of the safety dynamics of our processes: the \emph{reversibility} probabilities of the \textbf{Slush} process. All the other formal results in this paper are, informally speaking, intuitive derivations and augmentations of this result.

\begin{theorem}
Prenons la configuration du système à l'instant $t$ comme étant $\mathcal{S}_t = n/2 + \delta$, ce qui signifie que le
réseau a dérivé de $2\delta$ noeuds bleus de plus que les noeuds rouges ($\delta = 0$ signifie que rouges et bleus
sont en nombre égal). $\xi_\delta$ étant la probabilité d'un basculement vers l'état où tous les noeuds sont rouges,
nous avons donc pour tout $0 \leq \delta \leq n/2$
\begin{equation}
\begin{split}
    \xi_\delta &\leq \left(\dfrac{1/2 - \delta/n}{\alpha/k}\right)^{\alpha}\left(\dfrac{1/2 + \delta/n}{1- \alpha/k}\right)^{k-\alpha}\\
    &\leq e^{-2((\alpha/k) - (1/2) + (\delta/n))^2 k}
\end{split}
\end{equation}
\end{theorem}

\begin{proof}
Cette borne suit les bornes de queue dérivées de Hoeffding de la distribution hypergéométrique définie par
Chvatal~\cite{chvatal1979tail}.
\end{proof}

%O \begin{theorem}
%O Let the configuration of the system at time $t$ be $\mathcal{S}_t = n/2 + \delta$, meaning that the network has drifted to $2\delta$ more blue nodes than red nodes ($\delta = 0$ means that red and blue are equal). Let $\xi_\delta$ be the probability of absorption to the all-red state (minority). Then, for all $0 \leq \delta \leq n/2$, we have
%O \begin{equation}
%O \begin{split}
%O     \xi_\delta &\leq \left(\dfrac{1/2 - \delta/n}{\alpha/k}\right)^{\alpha}\left(\dfrac{1/2 + \delta/n}{1- \alpha/k}\right)^{k-\alpha}\\
%O     &\leq e^{-2((\alpha/k) - (1/2) + (\delta/n))^2 k}
%O \end{split}
%O \end{equation}
%O \end{theorem}

%O \begin{proof}
%O This bound follows from the Hoeffding-derived tail bounds of the hypergeometric distribution by Chvatal~\cite{chvatal1979tail}.
%O \end{proof}

Nous notons que les bornes de Chvatal sont introduites ici dans un but de simplification et sont extrêmement faibles.
Nous laissons l'expression dans sa forme complète dans le Théorème~\ref{theorem:slush_prob_convergence_minority}
disponible en annexe, qui est aussi bien plus fort que la borne de Chvatal.
Néanmoins, l'utilisation de la borne de Chvatal nous permet de faire l'observation qui consiste à dire qu'au fur et à
mesure que la dérivation $\delta$ augmente, pour un $\alpha$ et un $k$ constants, la probabilité de basculer vers la
valeur minoritaire décroît \emph{de manière exponentielle} (en fait encore plus rapidement vu qu'il y a un terme
quadratique dans l'exposant inverse). De plus, la même observation est valable si l'on fait croître $\alpha$ en gardant
$k$ constant.

Les conclusions de ce théorème démontreint une propriété clé du système: une fois que le réseau perd sa bivalence
(ex: $\delta > 0$), il tend à se renverser et converger rapidement vers la couleur majoritaire et il devient alors
suffisamment improbable qu'il rebascule vers la couleur minoritaire. C'est cette propriété fondamentale que nous
exploitons dans nos protocoles, et ce qui les rend sûrs malgré le fait que l'échantillonnage se fait sur une petite
partie du réseau de taille fixe. Le résultat principal qui s'en suit pour les garanties de sûreté de Snowflake consiste
à trouver des régions (à partir de paramètres spécifiquement choisis) où la réversibilité n'est possible qu'à partir
d'une probabilité maximale $\varepsilon$ même en conditions d'adversité.

%O We note that Chvatal's bounds are introduced for simplicity of exposition and are extremely weak.
%O We leave the full closed-form expression in Theorem~\ref{theorem:slush_prob_convergence_minority} to the appendix, which is also significantly stronger than the Chvatal bound.
%O Nonetheless, using the loose Chvatal bound, we make the key observation that as the drift $\delta$ increases, given fixed $\alpha$ and $k$, the probability of moving towards the minority value decreases \emph{exponentially fast} (in fact, even faster, since there is a quadratic term in the inverse exponent). Additionally, the same result holds for increasing $\alpha$ given a fixed $k$.
%O
%O The outcomes of this theorem demonstrate a key property: once the network loses full bivalency (i.e. $\delta > 0$), it tends to topple and converge rapidly towards the majority color, unable to revert back to the minority with significant probability. This is the fundamental property exploited by our protocols, and what makes them secure despite only sampling a small, constant-sized set of the network. The core result that follows for the safety guarantees in Snowflake is in finding regions (given specific parameter choices) where the reversibility holds with no higher than $\varepsilon$ probability even under adversarial presence.

\paragraph{Snowflake}

Dans le cas de Snowflake, nous prenons comme hypothèse qu'une partie des noeuds est antagoniste. Avec Slush, une
fois que le réseau obtient une majorité significative pour l'une des propositions (ex: la couleur bleue), il devient
improbable qu'une proposition minoritaire (ex: la couleur rouge) puisse être adoptée dans le futur (irréversibilité).
De plus, les noeuds Slush ont simplement besoin d'exécuter le protocole pour un nombre déterministe $m$ de tours qui
est connu en amont de l'exécution du protocole. Lorsqu'on introduit des noeuds antagonistes qui suivent des stratégies
arbitraires, les noeuds ne peuvent simplement plus exécuter le protocole pour un nombre déterministe de tours vu que
les adversaires peuvent affecter la valeur de $m$ de manière non déterministe. A la place, les noeuds légitimes doivent
implémenter un mécanisme pour explicitement détecter que l'irréversibilité a été atteinte. Dans ce but, dans Snowflake
chaque noeud légitime implémente une fonction de décision, $\mathcal{D}(u, \mathcal{S}_t, blue) \rightarrow \{0, 1\}$,
qui est une variable aléatoire qui retourne $1$ si le noeud $u$ détecte que l'état d'irréversibilité a été atteint à
l'instant $t$ pour bleu. Ce mécanisme de décision est probabiliste, ce qui veut dire qu'il peut échouer, même s'il est
conçu pour que la probabilité de cet échec soit négligeable. Nous pouvons maintenant ébaucher la preuve de Snowflake.

\noindent \emph{Ebauche de preuve}. Nous définissons la stratégie d'échec comme étant l'évênement lors duquel deux
noeuds légitimes $u$ et $v$ décident entre le bleu et le rouge, ex: $\mathcal{D}(u, \mathcal{S}_t, bleu) \rightarrow 1$
et $\mathcal{D}(v, \mathcal{S}_{t'}, rouge) \rightarrow 1$, pour deux instants $t$ et $t'$. Nous modélisons une fois de
plus le système comme un processus à temps aléatoire. L'espace des états est défini de la même manière que pour Slush.
Néanmoins, nous observons des subtilités critiques. Tout d'abord, même si tous les noeuds légitimes acceptent une
couleur, les noeuds byzantins peuvent toujours basculer vers l'autre couleur. Ensuite nous devons aussi prendre en
considération le mécanisme de décision $\mathcal{D}(*)$. Pour cette analyse, nous nous affranchissons du besoin de
garder l'historique de toutes les configurations du réseau soumises à toutes les stratégies antagonistes et prenons pour
hypothèse qu'un noeud $u$ décide d'abord d'adopter la couleur bleue. Ensuite en fonction de l'état du réseau suite à la
décision de $u$, nous calculons la probabilité qu'un autre noeud $v$ adopte le rouge, qui est fonction à la fois de la
probabilité que le réseau bascule vers l'état minoritaire bleu et que $v$ bascule vers cet état.
Nous démontrons qu'en choisissant correctement $k$, $\alpha$, et $\beta$, nous pouvons construire des instances
extrêmement sécurisées de Snowflake (ex: échec de sécurité avec une probabilité de $\leq \varepsilon$) quand le réseau
atteint un biais de $\delta$, comme le montre la Figure~\ref{fig:states_feasible_solutions}. Un exemple concret est
présenté dans la Figure~\ref{fig:fandepsilon}.

\begin{figure}[h]
\begin{center}
\input{figures/analysis2}
\caption{Représentation de l'état d'irréversibilité qui existe quand -- même en la présence de $f$ noeuds byzantins --
  le nombre de noeuds légitimes bleus dépasse le nombre de noeuds légitimes rouges de plus de $2\delta$.
}
\label{fig:states_feasible_solutions}
\end{center}
\end{figure}

%O \paragraph{Snowflake}
%O For Snowflake, we assume that some fraction of nodes are adversarial. In Slush, once the network gains significant majority support for one proposal (e.g., the color blue), it becomes unlikely for a minority proposal (e.g., the color red) to ever become decided in the future (irreversibility). Furthermore, in Slush nodes simply have to execute the protocol for a deterministic number of rounds, $m$, which is known ahead of protocol execution. When introducing adversarial nodes with arbitrary strategies, however, nodes cannot simply execute the protocol for a deterministic number of rounds, since the adversary may nondeterministically affect the value of $m$. Instead, correct nodes must implement a mechanism to explicitly detect that irreversibility has been reached. To that end, in Snowflake, every correct node implements a decision function, $\mathcal{D}(u, \mathcal{S}_t, blue) \rightarrow \{0, 1\}$, which is a random variable that outputs $1$ if node $u$ detects that the network has reached an irreversibility state at time $t$ for blue. The decision mechanism is probabilistic, meaning that it can fail, although it is designed to do so with negligible probability. We now sketch the proof of Snowflake.
%O
%O \noindent \emph{Proof Sketch}. We define safety failure to be the event wherein any two correct nodes $u$ and $v$ decide on blue and red, i.e. $\mathcal{D}(u, \mathcal{S}_t, blue) \rightarrow 1$ and $\mathcal{D}(v, \mathcal{S}_{t'}, red) \rightarrow 1$, for any two times $t$ and $t'$. We again model the system as a continuous time random process. The state space is defined the same way as in Slush. However, we note some critical subtleties. First, even if all correct nodes accept a color, the Byzantine nodes may revert. Second, we also have to consider the decision mechanism $\mathcal{D}(*)$. To analyze, we obviate the need to keep track of all network configurations under all adversarial strategies and assume that a node $u$ first decides on blue. Then, conditioned on the state of the network upon $u$ deciding, we calculate the probability that another node $v$ decides red, which is a function of both the probability that the network reverts towards a minority blue state and that $v$ decides at that state.
%O We show that under appropriate choices of $k$, $\alpha$, and $\beta$, we can construct highly secure instances of Snowflake (i.e. safety failure with probability $\leq \varepsilon$) when the network reaches some bias of $\delta$, as shown in Figure~\ref{fig:states_feasible_solutions}. A concrete example is provided in Figure~\ref{fig:fandepsilon}.
%O
%O \begin{figure}[h]
%O \begin{center}
%O \input{figures/analysis2}
%O \caption{Representation of the irreversibility state, which exists when -- even under $f$ Byzantine nodes -- the number of blue correct nodes exceeds that of red correct nodes by more than $2\delta$.
%O }
%O \label{fig:states_feasible_solutions}
%O \end{center}
%O \end{figure}

% An important insight is that there exists an irreversible state, or \textit{point of no return}, after which the system will converge to an absorbing state whp. Furthermore a correct node only decides when the system is beyond the point of no return. Composing these two guarantees together, the probability of a safety violation is strictly less than $\varepsilon$, which can be configured as desired.
% Unsurprisingly, there is an inherent tension between safety and liveness, but suitable parameters can be found that are practical.
% Larger values of $k$ obtain higher levels of security for correct nodes, at the expense of slower convergence.

\paragraph{Snowball}

Snowball est une amélioration en terme de sécurité par rapport à Snowflake, où les perturbations aléatoires dans les
échantillons du réseau sont réduites par l'introduction d'une forme limitée d'historique que l'on appelle confiance.

\noindent \emph{Ebauche de preuve}. Nous appliquons des inégalités de concentration pour prouver qu'une fois le système
ayant atteint l'état d'irréversibilité, alors l'évolution de la confiance envers la couleur majoritaire adoptée va
augmenter constamment et dériver de plus en plus loin des noeuds de couleur minoritaire, jusqu'à rendre la réversibilité
de plus en plus improbable avec le temps. Si cette dérive finit par se retourner, alors l'analyse de la réversibilité
devient identique à celle de Snowflake.

%O \paragraph{Snowball}
%O Snowball is an improvement in security over Snowflake, where random perturbations in network samples are reduced by introducing a limited form of history, which we refer to as confidence.
%O % Modeling Snowball with a Markov chain is difficult because of a state space explosion problem. In particular, it is not sufficient to simply keep track of color preferences of each correct node, the analysis must also maintain information about their confidence.
%O
%O \noindent \emph{Proof Sketch}. We apply martingale concentration inequalities to prove that once the system has reached the irreversibility state, then the growth of the confidence of the majority decided color will perpetually grow and drift further away from those of the minority color, effectively rendering reversibility less likely over time. If the drifts ever revert, then reversibility analysis becomes identical to that of Snowflake.

\subsection{Vitalité}

Nous prenons pour hypothèse la présence antagoniste observée $0 \leq f' \leq n(k - \alpha - \psi)/k \leq f$, où $\psi$
représente la zone tampon.
Plus $\psi$ est grand, plus la capacité du mécanisme de décision à tendre vers une valeur est rapide. Si bien sûr $\psi$
tend vers zéro ou devient négatif alors nous dépassons la limite supérieure de tolérance antagoniste pour le système
paramétré, en conséquence l'attaquant peut, avec une haute probabilité, bloquer la convergence en choisissant simplement
de ne pas répondre, et ceci même si les garanties de sûreté s'appliquent toujours.

En partant de $\psi$ strictement positif, la convergence est strictement finie pour toutes les configurations où une
proposition a un support d'au moins $\alpha$. De plus, non seulement la convergence est finie avec une probabilité de
un, mais nous avons aussi une probabilité strictement positive de convergence jusqu'à un instant borné $t_{max}$, comme
décrit dans la Proposition~\ref{lemma:finitetermination}, qui découle du Théorème~\ref{theorem:mean-convergence-time}.
Cela précise la propriété de vitalité P2.

\noindent \emph{Ebauche de preuve}. En utilisant la construction du système pour prouver l'irréversibilité, nous
caractérisons la distribution de la moyenne du temps passé (les périodes "sojourn") dans chaque état avant que le
système ne termine son exécution en adoptant l'un des états. Ce temps de convergence est l'union de ces périodes.

Pour les transactions non conflictuelles, vu que l'attaquant est incapable de générer un conflit, le temps de décision
est simplement le temps de mélange, qui est $\Oh{\log{n}}$. La vitalité guarantit qu'une configuration de réseau
entièrement bivalent atteint un temps de convergence optimal de $\Oh{\log{n}}$ tours si le nombre d'attaquants est au
plus $\Oh{\sqrt{n}}$, pour $\alpha = \floor{k/2} + 1$. Nous donnons plus de détails dans la
Proposition~\ref{lemma:centrallimit}.
Quand le nombre de noeuds antagonistes dépasse $\Oh{\sqrt{n}}$, le nombre le plus pessimiste de tours grandit de manière
polynomiale, et quand $f$ tend vers $n/2$ ce nombre de tours tend vers des taux de convergence exponentiels.

\noindent \emph{Ebauche de preuve}. Nous modifions le Théorème~\ref{theorem:mean-convergence-time} en y incluant le
nombre de nodes antagonistes, ce qui annule toute déséquilibre dans le réseau en le gardant entièrement bivalent.

%O \subsection{Liveness}
%O
%O We assume that the observed adversarial presence $0 \leq f' \leq n(k - \alpha - \psi)/k \leq f$, where we refer to $\psi$ as the buffer zone.
%O The bigger $\psi$, the quicker the ability of the decision mechanism to finalize a value.
%O If, of course, $\psi$ approaches zero or becomes negative, then we violate the upper bound of adversarial tolerance for the parameterized system, and thus the adversary can, with high probability, stall termination by simply choosing to not respond, although the safety guarantees may still hold.
%O
%O Assuming that $\psi$ is strictly positive, termination is strictly finite under all network configurations where a proposal has at least $\alpha$ support. Furthermore, not only is termination finite with probability one, we also have a strictly positive probability of termination within any bounded amount of time $t_{max}$, as discussed in Lemma~\ref{lemma:finitetermination}, which follows from Theorem~\ref{theorem:mean-convergence-time}. This captures liveness property P2.
%O
%O \noindent\emph{Proof Sketch.} Using the construction of the system to prove irreversibility, we characterize the distribution of the average time spent (sojourn times) at each state before the system terminates execution by absorption at either absorbing state. The termination time is then a union of these times.
%O
%O For non-conflicting transactions, since the adversary is unable to forge a conflict, the time to decision is simply the mixing time , which is $\Oh{\log{n}}$.
%O Liveness guarantees under a fully bivalent network configuration reduce to an optimal convergence time of $\Oh{\log{n}}$ rounds if the adversary is at most $\Oh{\sqrt{n}}$, for $\alpha = \floor{k/2} + 1$. We leave additional detains to Lemma~\ref{lemma:centrallimit}.
%O % This result is independently supported by Ben-Or~\cite{ben1983another} and Doerr et al~\cite{doerr2011stabilizing}.
%O When the adversary surpasses $\Oh{\sqrt{n}}$ nodes, the worst-case number of rounds increases polynomially, and as $f$ approaches $n/2$ it approaches exponential convergence rates.
%O
%O \noindent\emph{Proof Sketch.} We modify Theorem~\ref{theorem:mean-convergence-time} to include the adversary, which reverts any imbalances in the network by keeping network fully bivalent.

\paragraph{Consensus multi-valeur}

Notre protocole de consensus binaire pourrait supporter des consensus multi-valeur en exécutant des instances binaires
logarithmiques, une pour chaque bit de la valeur proposée. Cependant, une telle réduction théorique n'est pas
forcément efficace en pratique. A la place, nous pourrions directement incorporer des valeurs multiples comme des
couleurs multiples dans le protocole en permettant toujours la généralisation de l'analyse de sûreté.

Pour ce qui est de la vitalité nous ébauchons en Annexe~\ref{sec:sync-heuristic} un mécanisme d'initialisation sans
leader, qui de toute attente nécessite $\Oh{\log{n}}$ tours dans l'hypothèse que le réseau soit synchronisé. Bien que
la conception de ce mécanisme soit intéréssante, il est à noter qu'un tel mécanisme n'est pas nécéssaire pour un système
de paiement décentralisé, comme nous le démontrons en Section~\ref{sec:implementation}.
Finalement, nous développons les divergences entre vues et pertes en Annexe~\ref{sec:full-analysis-churn}.

%0 \paragraph{Multi-Value Consensus}
%0 Our binary consensus protocol could support multi-value consensus by running logarithmic binary instances, one for each bit of the proposed value. However, such theoretical reduction might not be efficient in practice. Instead, we could directly incorporate multi-values as multi-colors in the protocol, where safety analysis could still be generalized.
%0
%0 For liveness, we sketch a leaderless initialization mechanism, which in expectation uses $\Oh{\log{n}}$ rounds under the assumption that the network is synchronized in the Appendix~\ref{sec:sync-heuristic}.
%0 While the design of initialization mechanisms is interesting, note that it is not necessary for a decentralized payment system, as we show in Section~\ref{sec:implementation}.
%0 %We leave additional research into the initialization mechanisms to future work.
%0 %However, we finally note that when building a decentralized payment system, an initialization mechanism is not necessary, as we show in the implementation of Avalanche in Section~\ref{sec:implementation}.
%0 Finally, in the Appendix~\ref{sec:full-analysis-churn}, we discuss churn and view discrepancies.

% \subsection{Additional Insights}
% Two interesting insights arise from the way our protocols are designed and used.
% First, the protocols discussed in this work lead to both safety and liveness guarantees whose underlying function is smooth, rather than a step function.
% In many other consensus protocols, safety is guaranteed with up to a fixed threshold number (e.g.~1/3) of adversarial nodes, beyond which no guarantees are provided. In our protocols, the guarantees degrade gracefully with an adversarial percentage beyond the pre-established bound. For example, optimal system parameters can be chosen to tolerate precisely 1/5 adversarial presence with failure probability $\varepsilon$. However, if the system faces an adversarial presence greater than 1/5, then the probability of failure degrades to slightly above $\varepsilon$, rather than immediately to $1$.
% Second, these protocols externalize the safety and liveness tradeoffs.
% The system designer may choose to guarantee safety even under catastrophic events, such as an adversarial presence beyond $1/2$, at the expense of liveness.
% This presents a powerful knob not available in classical or Nakamoto-based consensus protocols.

% \begin{compactitem}
% \item\textbf{Eventually good ancestry.} Virtuous transactions can be retried by picking new parents, selected from a set that is more likely to be preferred.
% Ultimately, one can always attach a transaction to decided parents to completely mitigate this risk.
% \Jon{So why don't we always do this? Later the paper clarifies that moving up the chain reduces the efficiency
%     and increases latency for the proposed transaction. I got pretty lost in the last two paragraphs of section 4}
% A simple technique for parent selection is to select new parents for a virtuous transaction at successively lower heights in the DAG, proceeding towards the genesis vertex.
% This procedure is guaranteed to terminate with uncontested, decided parents, ensuring that the transaction cannot suffer liveness failure due to rogue transactions.

% \item\textbf{Sufficient chits.} A secondary mechanism is necessary to ensure that virtuous transactions with decided ancestry will receive sufficient chits.
% To ensure this, correct nodes examine the DAG for virtuous non-nop transactions that lack sufficient progeny and emit nop transactions to help increase their confidence.
% A nop transaction has just one parent and no application side-effects, and can be issued by any node. They cannot be abused by Byzantine nodes because, even though nops trigger new queries, they do not automatically grant chits.

% With these two mechanisms in place, it is easy to see that, at worst, Avalanche will degenerate into separate instances of Snowball, and thus provide the same liveness guarantee for virtuous transactions.
% \end{compactitem}

%XXX discuss how no-ops can be implemented

% \subsection{Communication Complexity}\tronly{}{\vspace{-0.5em}}
% Since liveness is not guaranteed for rogue transactions, we focus our message complexity analysis solely for the case of virtuous transactions.
% For the case of virtuous transactions, Snowflake and Snowball are both guaranteed to terminate after $O(kn\log n)$ messages.
% This follows from the well-known results related to epidemic algorithms\cite{demers1987epidemic}, and is confirmed by Table~\ref{table:growth_worst_case} in Appendix~\ref{sec:full-analysis}.

\section{Système de paiement pair à pair}
\label{sec:implementation}

%\label{sec:evaluation}

%O Using Snowball consensus, we have implemented a bare-bones payment system, Avalanche, which supports Bitcoin transactions. In this section, we describe the design and sketch how the implementation can support the value transfer primitive at the center of cryptocurrencies.
Grâce au consensus Snowball, nous avons implémenté un système de paiement simpliste, Avalanche, qui supporte les transactions Bitcoin. Dans cette section, nous en décrivons la conception et schématisons la manière dont l'implémentation peut supporter la primitive de transfert de valeur au cœur des cryptomonnaies.
%O Deploying a full cryptocurrency involves bootstrapping, minting, staking, unstaking,
%O and inflation control. While we have solutions for these issues, their full
%O discussion is beyond the scope of this paper, whose focus is centered on the
%O novel Snow consensus protocol family.
Le déploiement complet d'une cryptomonnaie implique l'initialisation, l'émission, le dépôt, le retrait et le contrôle de l'inflation. Nous disposons de solutions à ces problèmes mais leur description détaillée sort du cadre de cet article, dont l'objet est la nouvelle famille de consensus Snow. % HOULA staking unstaking
%In this section,
%we focus on how Avalanche can support the value transfer primitive at the center of cryptocurrencies.
%\paragraph{XXX: the original implementation paragraph in Model}

%The Snow family is presented in the form of single-decree, binary consensus for its own theoretical value and simplicity.
%On the other hand, we show later in Section~\ref{sec:implementation} our practical payment system, Avalanche, utilizes multiple Snowball instances to support standard Bitcoin-like transactions. %, by humbly cheating in two ways.
%First, instead of a single replicated state machine (RSM) model, where the system determines a sequence of totally-ordered transactions $T_0, T_1, T_2, \ldots$ issued by any client, we adopt a \emph{parallel consensus model}, where each client interacts independently with its own RSMs and optionally transfers ownership of its RSM to another client. The system establishes only a partial order between dependent transactions.
%Second,
%O In a cryptocurrency setting, cryptographic signatures enforce that only a key owner is able to create a transaction that spends a particular coin. Since correct clients follow the protocol as prescribed and never double spend coins, in Avalanche, they are guaranteed both safety and liveness for their \emph{virtuous} transactions. In contrast, liveness is not guaranteed for \emph{rogue} transactions, submitted by Byzantine clients, which conflict with one another. Such decisions may stall in the network, but have no safety impact on virtuous transactions.
Dans une configuration de cryptomonnaie, les signatures cryptographiques imposent que seul le possesseur de la clef soit capable de créer une transaction dépensant un dépôt donné. Comme les clients corrects suivent le protocole tel qu'il est prescrit et ne peuvent pratiquer la double dépense, ils ont la garantie tant de sûreté de fonctionnement que de vitalité pour leurs transactions \emph{vertueuses}. Par contraste, la vitalité n'est pas garantie pour les transactions \emph{malveillantes} soumises par des clients byzantins, lesquelles entrent mutuellement en conflit. Ces décisions peuvent arrêter le réseau mais n'ont pas d'impact sur les transactions vertueuses.
%O We show that this is a sensible tradeoff, and that the resulting system is sufficient for building complex payment systems.
Nous montrons que ce compromis est raisnnable et que le système qui en résulte suffit à bâtir des systèmes de paiement complexes.

\input{avalanche_fr}

%O \subsection{Multi-Input UTXO Transactions}
\subsection{Transactions à UTXO multi-entrées}
%O In addition to the DAG structure in Avalanche, an \emph{unspent transaction output} (UTXO)~\cite{nakamoto2008bitcoin} graph that captures
%O spending dependency is used to realize the ledger for the payment system. To
%O avoid ambiguity, we denote the transactions that encode the data for money
%O transfer \emph{transactions}, while we call the
%O transactions ($T \in \mathcal{T}$) in Avalanche's DAG \emph{vertices}.
En addition à la structure de DAG dans Avalanche, un graphe de \emph{unspent transaction output} (UTXO)~\cite{nakamoto2008bitcoin}, ou sortie de transaction non dépensée, qui capture les dépendances des dépenses est utilisé pour réaliser le registre du système de paiement. Pour lever toute ambiguïté, nous appelons les transactions qui codent les données de transfert d'argent \emph{transactions} alors que nous appelons les transactions ($T \in \mathcal{T}$) dans le DAG d'Avalanche des \emph{sommets}.

%\tronly
%{
%Each transaction represents a money transfer that takes several inputs from
%source accounts and generates several outputs to destinations. As a UTXO-based system
%that keeps a decentralized ledger, balances are kept by the \emph{unspent outputs}
%of transactions.
%
%More specifically, a transaction $\texttt{TX}_a$ maintains
%a list of inputs: $\texttt{In}_{a1}$, $\texttt{In}_{a2}$, $\cdots$. Each input
%has two fields: the reference to an unspent transaction output and a spend script.
%The unspent transaction output uniquely refers to an output of a previously made transaction.
%The script snippet will be prepended to the script from the referred output forming a complete computation.
%It could typically be a cryptographic proof of validity, but could also be any Turing-complete
%computation in general.
%Each output $\texttt{Out}_{a1}$, $\texttt{Out}_{a2}$, $\cdots$,
%contains some amount of money and a script which typically contains cryptographic verification that takes the proof from the future input and verifies validity.
%
%In our payment system, there are \emph{addresses} representing different
%accounts by cryptographic keys. The public
%key is used as the identity for recipients in the output scripts, while
%the private key is for creating signatures in the
%input scripts, spending the available funds. Only the key owner is able spend the unspent output by creating an input with
%the signature in a new transaction.
%
%Due to the possibility of double spending by the private key owner,
%cryptocurrencies such as Bitcoin use a blockchain as the linear log to reject the
%transaction that comes later in the log and tries to spend some output twice.
%Instead, in our payment system, we use Avalanche to resolve the double-spend
%conflicts in each conflict set, without maintaining a linear log.
%
%If we could assume each transaction can only have one single input, the
%initialization of Avalanche would be straightforward. We let each vertex on the
%underlying DAG be one transaction.  The conflict set in Avalanche is the set of
%transactions that try to spend the same unspent output. The conflict sets are
%disjoint because each transaction only has one input spending one
%unspent output, and thus belongs to exactly one set.
%
%%If we support transactions with multiple inputs using the same
%%method as in single-input case, we will violate the disjoint conflict set model assumed by
%%Avalanche, because the double spending relation between transactions with multiple
%%inputs is not transitive: $\texttt{TX}_a$ may double spend the same output with
%%$\texttt{TX}_b$ due to the same input value $\texttt{In}_{a1} =
%%\texttt{In}_{b1}$, and $\texttt{TX}_b$ might double spend with $\texttt{TX}_c$
%%due to $\texttt{In}_{b2} = \texttt{In}_{c1}$, but $\texttt{TX}_a$ may not
%%double spend with $\texttt{TX}_c$ at all.
%
%Multi-input transactions consume multiple UTXOs, and in Avalanche, may appear in multiple conflict sets.
%To account for these correctly, we represent \emph{transaction-input} pairs (e.g. $\texttt{In}_{a1}$) as an Avalanche vertex,
%and use the conjunction of \textsc{isAccepted} for all inputs of a transaction to ensure that no transaction will be accepted unless all its inputs are accepted.
%Since the acceptance for each pair is meaningful for
%the payment system only if all pairs from the same transaction are accepted, we can tie the fate of these
%pairs from the same transaction together by a single, bundled query: the queried
%node will only answer ``yes'' if all of the pairs are strongly preferred
%according to the DAG\@. This more conservative predicate will not undermine safety because merely introducing transactions that gather no chits will not increase confidence value in the
%protocol.
%
%\begin{figure}[t]
%\begin{center}
%    \input{figures/cash-system-a}
%    \captionof{figure}{The actual DAG implementation at transition granularity.}
%    \label{fig:cash-system-a}
%\end{center}
%\end{figure}
%
%Figure~\ref{fig:cash-system-a} demonstrates the actual implementation where the DAG is built at transaction granularity, whereas Figure~\ref{fig:cash-system-b} shows the equivalent logic of the underlying protocol, where vertices are at transaction-input granularity.
%}
%{
%O We inherit the transaction and address mechanisms from Bitcoin. At their simplest, transactions consist of multiple inputs and outputs, with corresponding redeem scripts.
Nous héritons les mécanismes de transaction et d'adresse de Bitcoin. En simplifiant à l'extrême, les transactions consistent en multiples entrées et sorties, avec les scripts d'échange correspondants.
%O Addresses are identified by the hash of their public keys, and signatures are generated by corresponding private keys.
Les adresses sont identifiées par l'empreinte de leurs clefs publiques et les signatures sont générées par les clefs privées.
%0 The full scripting language is used to ensure that a redeem script is authenticated to spend a UTXO\@.
Le langage de script est utilisé pour s'assurer qu'un script d'échange est authentifié pour dépenser une UTXO\@.
%O UTXOs are fully consumed by a valid transaction, and may generate new UTXOs spendable by named recipients.
Les UTXO sont totalement consommées par une transaction valide et peut engendrer de nouvelles UTXO que des destinataires nommés peuvent dépenser.
%O Multi-input transactions consume multiple UTXOs, and in Avalanche, may appear in multiple conflict sets.
Les transactions multi-entrées consomment plusieurs UTXO et, dans Avalanche, peuvent apparaître dans plusieurs ensembles de conflits.
%O To account for these correctly, we represent \emph{transaction-input} pairs (e.g. $\texttt{In}_{a1}$) as Avalanche vertices.
Pour les prendre correctement en compte, nous représentons les paires d'entrées de transactions (\emph{transaction-input}), par exemple $\texttt{In}_{a1}$, comme des sommets Avalanche.
%O The conflict relation of transaction-input pairs is transitive because of each pair only spends one unspent output.
La relation des conflits de paires de sorties de transation est transitive car une seule paire ne dépense qu'une sortie non dépensée.
%O Then, we use the conjunction of \textsc{isAccepted} for all inputs of a transaction to ensure that no transaction will be accepted unless all its inputs are accepted (Figure~\ref{fig:cash-system-b}). In other words, a transaction is accepted only if all its transaction-input pairs are accepted in their respective Snowball conflict sets.
Nous utilisons la conjonction de \textsc{isAccepted} pour toutes les entrées d'une transaction pour nous assurer qu'aucune transaction ne sera acceptée à moins que toutes ses entrées ne soient acceptées (Figure~\ref{fig:cash-system-b}). En d'autres termes, une transaction n'est acceptée que si toutes ses paires d'entrées de transaction sont acceptées dans leurs ensembles de conflits Snowball respectifs.
%O Following this idea, we finally implement the DAG of transaction-input pairs such that multiple
%O transactions can be batched together per query.
Selon cette idée, nous pouvons finalement implémenter le DAG des paires d'entrées de transactions tel que plusieurs transactions peuvent être regroupées par requête.

%}

%However, supporting only a single input is both inconvenient and inefficient.
%One has to issue multiple transactions to merge the unspent balance in order to
%make larger payments. Moreover, with more than one output, the growth of unspent output
%set (i.e. UTXO set) size could be exponential, causing
%trouble for maintenance. However, if we also require a single output for
%all transactions, the granularity of coins cannot be changed, and one
%separated transaction is needed for transfering each unit of the currency.

\begin{figure}[t]
\begin{center}
    \input{figures/cash-system-b}
%O     \captionof{figure}{The underlying logical DAG structure used by Avalanche.
%O     The tiny squares with shades are dummy vertices which just help form the
%O     DAG topology for the purpose of clarity, and can be replaced by direct
%O     edges. The rounded gray regions are the conflict sets.}\label{fig:cash-system-b}
    \captionof{figure}{La structure de DAG logique sous-jacente utilisée par Avalanche.
    Les petits carrés avec des ombres sont des sommets fictifs qui ne servent qu'à former
    la topologie du DAG dans un but de clarté, et peuvent être remplacés par des arêtes
    directes. Les régions grises arrondies sont les ensembles de conflits.}\label{fig:cash-system-b}
\end{center}
\end{figure}

%\noindent\textbf{Parent Selection.}
%The goal of the parent selection algorithm is to yield a well-structured DAG
%that maximizes the likelihood that virtuous transactions will be quickly
%accepted by the network. While this algorithm does not affect the safety of the
%protocol, it affects liveness and plays a crucial role in determining the shape of the
%DAG\@. A good parent selection algorithm grows the DAG
%in depth with a roughly steady ``width.'' The DAG should not diverge like a
%tree or converge to a chain, but instead should provide concurrency so nodes can work on multiple fronts.
%
%There are inherent trade-offs in the parent selection algorithm: selecting well-accepted parents makes it
%more likely for a transaction to find support, but can lead to vote dilution. Further, selecting more
%recent parents at the frontier of the DAG can lead to stuck transactions, as the parents may turn out
%to be rogue and remain unsupported.  In the following discussion, we illustrate this dilemma.
%We assume that every transaction will select a small number, $p$, of parents.
%We focus on the selection of eligible parent set, from which a subset of size $p$ can be chosen arbitrarily.
%%\Jon{Why is it important to choose parents randomly? What's the attack?}
%
%\tronly{
%Perhaps the simplest idea is to issue a fresh transaction with parents picked uniformly at random
%among those transactions that are currently strongly preferred. Specifically, we can adopt the predicate
%used in the voting rule to determine eligible parents on which a node would vote positively, as follows:
%\[
%    \mathcal{E} = \{T: \forall T\in\mathcal{T}, \textsc{isStronglyPreferred}(T)\}.
%\]
%
%But this strategy will yield large sets of eligible parents, consisting mostly of historical, old transactions.
%When a node samples the transactions uniformly from $\mathcal{E}$, the resulting DAG
%will have large, ever-increasing fan-out. Because new transactions will have scarce progenies,
%the voting process will take a long time to build the required confidence on any given new transaction.
%
%In contrast, efforts to reduce fan-out and control the shape of the DAG by selecting the recent transactions at
%the decision frontier suffer from another problem. Most recent transactions will have very low confidence,
%simply because they do not have enough descendants. Further, their conflict sets may not be well-distributed
%and well-known across the network, leading to a parent attachment under a transaction that will never be supported.
%This means the best parent candidates lie somewhere near the frontier, but not too far deep in history.
%
%The adaptive parent selection algorithm chooses parents by starting at the DAG frontier and retreating towards the
%genesis vertex until finding an eligible parent.
%}{
%The frontier transactions are those that currently do not have any children in the node's
%$\mathcal{T}$.  The set of strongly preferred transactions $\mathcal{E}$ is
%filtered by an additional criterion that the confidence should be larger than
%zero if the transaction has known conflicts. This filters out 0-confidence transactions from
%unstable conflict sets.  If there exist $p$ transactions
%in the filtered $\mathcal{E}$, then the adaptive selection will yield these transactions.
%
%Otherwise, the algorithm tries the parents of the transactions in $\mathcal{E}$,
%thus increasing the chance of finding more stabilized transactions as it
%retreats.
%}
%%XXX issue no-ops after a timeout
%The retreating search is guaranteed to terminate when it reaches the genesis
%vertex.  Formally, the selected parents in this adaptive selection algorithm
%is:
%
%\begin{center}
%\begin{algorithmic}[1]
%    \small
%    \Function{parentSelection}{$\mathcal{T}$}
%    \tronly{}{\State $\mathcal{E} = \{T: \forall T\in\mathcal{T}, \textsc{isStronglyPreferred}(T)\}$.}
%        \State $\mathcal{E}' \assign \{T: \forall T\in\mathcal{E}, |\mathcal{P}_T| = 1 \lor d(T) > 0\}$.
%        \State \Return $\{T: T \in \mathcal{E}' \land \forall T'\in\mathcal{T}, T \gets T', T' \notin \mathcal{E}'\}$.
%    \EndFunction
%    \captionof{figure}{Adaptive parent selection.}
%\end{algorithmic}
%\end{center}

%O \paragraph{Optimizations}
\paragraph{Optimisations}
%O We implement some optimizations to help the system scale.
Nous implémentons quelques optimisations pour que le système puisse passer à l'échelle.
%O First, we use \emph{lazy updates} to the DAG, because the recursive definition for confidence may otherwise require a costly DAG traversal.
D'abord, nous utilisons des \emph{lazy updates}, des mises à jour retardées, du DAG, car la définition récursive de la confiance pourrait engendrer une traversée du DAG coûteuse.

%O We maintain the current $d(T)$ value for each active vertex on the DAG, and update it only when a descendant vertex gets a chit.
Nous maintenons la valeurs $d(T)$ courante pour chaque sommet actif sur le DAG, et nous ne le mettons à jour que quand un sommet de la progéniture obtient un \emph{chit}.
%O Since the search path can be pruned at accepted vertices, the cost for an update is constant if the rejected vertices have a limited number of descendants and the undecided region of
%O the DAG stays at constant size.
Comme le chemin de recherche peut être purgé sur des sommets acceptés, le coût d'une mise à jour est constant si les sommets rejetés ont un nombre limité de descendant et si la région non décidée du DAG reste de taille constante.
%O Second, the conflict set could be large in practice, because a rogue client can generate a large volume of conflicting transactions.
Ensuite, l'ensemble de conflits peut être vaste en pratique, car un client malveillant peut générer un volume important de transactions conflictuelles.
%O Instead of keeping a container data structure for each conflict set, we create a mapping from each UTXO to the preferred transaction that stands as the representative for the entire conflict set.
Au lieu de conserver une structure de données comme un conteneur pour chaque ensemble de conflits, nous créons une correspondance à partir de chaque UTXO vers la transaction préférée qui peut représenter tout l'ensemble de conflits.
%O This enables a node to quickly determine future conflicts, and the appropriate response to queries.
Cela permet à un nœud de déterminer rapidement les conflits à venir ainsi que la réponse appropriée aux requêtes.
%O Finally, we speed up the query process by terminating early as soon as the $\alpha$ threshold is met, without waiting for $k$ responses.
Enfin, nous accélérons le processus de requête en terminant au plus tôt, dès que le seuil $\alpha$ est atteint, sans attendre les $k$ réponses.

%The safety guarantees of Snowball can be mapped to those of Avalanche, which is a concrete instantiation of Snowball using a directed acyclic graph to amortize cost. 
%We note that the structure of the Avalanche DAG itself does not correspond to votes, which is a subtle difference between other consensus protocols that make usage of a DAG. The DAG is merely a performance optimization, and is itself entirely orthogonal to the consensus process.

%O \paragraph{DAG} Compared to Snowball, Avalanche introduces a DAG structure that entangles the fate of unrelated conflict sets, each of which is a single-decree instance.
\paragraph{DAG} Comparé à Snowball, Avalanche introduit une structure de DAG qui lie fortement le sort d'ensembles de conflits sans relation entre eux, chacun étant une instance à décret unique.
%O This entanglement embodies a tension: attaching a virtuous transaction to undecided parents helps propel transactions towards a decision, while it puts transactions at risk of suffering liveness failures when parents turn out to be rogue.
Cette intrication concrétise une tension : l'attachement d'une transaction à des parents non décidés contribue à la décision concernant les transactions, tandis que les transactions risquent des défaillances de vitalité quand les parents s'avèrent malveillants.
%O We can resolve this tension and provide a liveness guarantee with the aid of two mechanisms.
Nous pouvons résoudre cette tension et fournir une garantie de vitalité à l'aide de deux mécanismes.

%O First we adopt an adaptive parent selection strategy, where transactions are attached at the live edge of the DAG, and are retried with new parents closer to the genesis vertex. This procedure is guaranteed to terminate with uncontested, decided parents, ensuring that a transaction cannot suffer liveness failure due to contested, rogue transactions.
D'abord nous adoptons une stratégie adaptative de sélection des parents, où les transactions sont attachées sur le bord actif du DAG et sont réessayées avec de nouveaux parents plus proche du sommet genèse. Cette procédure garantit un achèvement avec des parents incontestés, assurant ainsi qu'une transaction ne peut souffrir de défaillance de vitalité en raison de transactions contestées et malveillantes.
%O A secondary mechanism ensures that virtuous transactions with decided ancestry will receive sufficient chits. Correct nodes examine the DAG for virtuous transactions that lack sufficient progeny and emit no-op transactions to help increase their confidence.
Un mécanisme secondaire s'assure que les transactions vertueuses avec une ascendance décidée reçoit suffisamment de \emph{chits}. Les nœuds corrects examinent le DAG pour y trouver des transactions vertueuses manquant d'une progéniture suffisante et émettent des transactions \emph{no-op} pour accroître leur confiance.
%O With these two mechanisms in place, it is easy to see that, at worst, Avalanche will degenerate into separate instances of Snowball, and thus provide the same liveness guarantee for virtuous transactions.
Ces deux mécanismes mis en place, il est facile de voir qu'au pire Avalanche dégénérera en instances distinctes de Snowball, fournissant ainsi la même garantie de vitalité pour les transactions vertueuses.

%O Unlike other cryptocurrencies~\cite{IOTA} that use graph vertices
%O directly as votes, Avalanche only uses a DAG for the purpose of batching queries
%O in the underlying Snowball instances.
Contrairement à d'autres cryptomonnaies~\cite{IOTA} qui utilisent directement les sommets du graphe comme votes, Avalanche n'utilise un DAG que pour regrouper les requêtes dans les instances Snowball sous-jacentes.

%O Because confidence is built by collected chits, and not by just the presence of
%O a vertex, simply flooding the network with vertices attached to the rejected
%O side of a subgraph will not subvert the protocol.
Comme la confiance est bâtie sur les \emph{chits} récoltés, et non simplement par la présence d'un sommet, la simple inondation du réseau par des sommets attachés à une partie rejetée du sous-graphe ne subvertit pas le protocole.

%O \subsection{Communication Complexity}
\subsection{Complexité des communications}
%O Let the DAG induced by Avalanche have an expected branching factor of $p$, corresponding to the width of the DAG, and determined by the parent selection algorithm.
Soit un facteur de ramification attendu de $p$ dans Avalanche, correspondant à la largeur du DAG, et déterminé par l'algorithme de sélection du parent.
%O Given the $\beta_1$ and $\beta_2$ decision threshold, a transaction that has just reached the point of decision will have an associated progeny $\mathcal{Y}$.
Étant donné le seuil de décision $\beta_1$ et $\beta_2$, une transaction qui vient d'atteindre le point de décision aura une progéniture associée $\mathcal{Y}$.
%O Let $m$ be the expected depth of $\mathcal{Y}$.
Soit $m$ la profondeur attendue de $\mathcal{Y}$.
%O If we were to let the Avalanche network make progress and then freeze the DAG at a depth $y$,
%O then it will have roughly $py$ vertices/transactions, of which $p(y - m)$ are decided in expectation.
Si nous devions permettre au réseau Avalanche de progresser puis de geler le DAG à une profondeur $y$, alors il aurait à peu près $py$ sommets/transactions, desquels on pourrait attendre que $p(y - m)$ soient décidés.
%O Only $pm$ recent transactions would lack the progeny required for a decision.
Seules $pm$ transactions récentes manqueraient de la progéniture nécessaires à une prise de décision.
%O For each node, each query requires $k$ samples, and therefore the total message cost per transaction is in expectation $(pky) / (p(y - m)) = ky/(y-m)$.
Pour chaque nœud, chaque requête demande $k$ échantillons, et donc on attend un coût total des messages par transaction de $(pky) / (p(y - m)) = ky/(y-m)$.
%O Since $m$ is a constant determined by the undecided region of the DAG as the system constantly makes progress, message complexity per node is $O(k)$, while the total complexity is $O(kn)$.
Comme $m$ est une constante déterminée par la région non décidée du DAG pendant que le système progresse constamment, la complexité en messages par nœuds est $O(k)$ alors que la complexité totale est $O(kn)$.

\section{Evaluation}
\label{sec:evaluation}
\input{sections/evaluation_fr}

\section{Related Work}
\label{sec:related-work}
\input{sections/related-work_fr}

\section{Conclusion}
\label{sec:conclusions}
This paper introduced a novel family of consensus protocols, coupled with the appropriate mathematical tools for analyzing them.
\tronly{These protocols are highly efficient and robust, combining the best features of classical and Nakamoto consensus.}
They scale well, achieve high throughput and quick finality, work without precise membership knowledge, and degrade gracefully under catastrophic adversarial attacks.

There is much work to do to improve this line of research. \tronly{
One such improvement could be the introduction of an adversarial network scheduler.
Another}{One} improvement would be to characterize the system's guarantees under an adversary whose powers are realistically limited, whereupon performance would improve even further. \tronly{Finally, more}{More} sophisticated initialization mechanisms would bear fruitful in improving liveness of multi-value consensus.
Overall, we hope that the protocols and analysis techniques presented here add to the arsenal of the distributed system developers and provide a foundation for new lightweight and scalable mechanisms.

%\section*{Acknowledgments}\tronly{}{\vspace{-0.5em}}
%\label{sec:related-work}
%We are grateful to the many individuals who provided feedback on earlier drafts. 
% Bobby Kleinberg, Vitalik Buterin, ...

%latex here should be the name of your bibtex file minus '.bib'
%\clearpage
\bibliographystyle{acm}
\bibliography{paper}
%\newpage
\begin{appendices}
%O \section{Analysis}
\section{Analyse}
\label{sec:full-analysis}
%O In this appendix, we provide an analysis of Slush, Snowflake and Snowball.
Cette annexe contient une analyse de Slush, Snowflake et Snowball.
%For lack of space, we leave additional details to an accompanying report.

%O \subsection{Preliminaries}
\subsection{Préliminaires}
%O We assume the network model as discussed in Section~\ref{sec:model_and_goals}. We let $\mathtt{R}$ (``red'') and $\mathtt{B}$ (``blue'') represent two generic conflicting choices.
Nous supposons le modèle réseau discuté en section~\ref{sec:model_and_goals}. Soient $\mathtt{R}$ (``rouge'') et $\mathtt{B}$ (``bleu'') représentant deux choix conflictuels génériques.
%O Without loss of generality, we focus our attention on counts of $\mathtt{B}$, i.e.\ the total number of nodes that prefer blue.
Sans perdre en généralité, nous portons notre attention sur les décomptes de $\mathtt{B}$, c'est-à-dire le nombre de nœuds qui préfèrent le bleu.

%O \paragraph{Hypergeometric Distribution} Each network query of $k$ peers corresponds to a sample without replacement out of a network of $n$ nodes, also referred to as a hypergeometric sample.
\paragraph{Distribution hypergéométrique} Chaque requête réseau de $k$ pairs correspond à un échantillon sans remplacement depuis un réseau de $n$ nœuds, également appelé un échantillon hypergéométrique.
%O We let the random variable $\mathcal{H}(\mathcal{N}, x, k) \rightarrow \{0, \dots, k\}$ denote the resulting counts of $\mathtt{B}$ in the sample (unless otherwise stated), where $x$ is the total count of $\mathtt{B}$ in the population. The probability that the query achieves the required threshold of $\alpha$ or more votes is given by:
La variable aléatoire $\mathcal{H}(\mathcal{N}, x, k) \rightarrow \{0, \dots, k\}$ note les décomptes résultant de $\mathtt{B}$ dans l'échantillon (sauf mention spécifique), où $x$ est le nombre total de $\mathtt{B}$ dans la population. La probabilité que la requête atteigne le seuil requis d'au moins $\alpha$ votes est donnée par :
\begin{equation}
\small
P(\mathcal{H}(\mathcal{N}, x, k) \geq \alpha) = \left.\sum_{j = \alpha}^{k} {x \choose j} {n - x \choose k - j} \middle/ {n \choose k}\right.
\label{eq:hypergeometric}
\end{equation}
%O For ease of notation, we overload $\mathcal{H}(*)$ by implicitly referring to $P(\mathcal{H}(\mathcal{N}, x, k) \geq \alpha)$ as $\mathcal{H}(\mathcal{N}, x, k, \alpha)$. 
Pour faciliter la notation, nous surchargeons $\mathcal{H}(*)$ en nous référant implicitement à $P(\mathcal{H}(\mathcal{N}, x, k) \geq \alpha)$ par $\mathcal{H}(\mathcal{N}, x, k, \alpha)$.

%O \paragraph{Tail Bounds On Hypergeometric Distribution} We can reduce some of the complexity in Equation~\ref{eq:hypergeometric} by introducing a bound on the hypergeometric distribution induced by $\mathcal{H}^k_{\mathcal{N},x}$.
\paragraph{Bornes de queue sur la distribution hypergéométrique} Nous pouvons un peu réduire la complexité de l'équation~\ref{eq:hypergeometric} en introduisant une borne sur la distribution hypergéométrique induite par $\mathcal{H}^k_{\mathcal{N},x}$.
%O Let $p=x/n$ be the ratio of support for $\mathtt{B}$ in the population.
Soit $p=x/n$ la proportion du support pour $\mathtt{B}$ dans la population.
%O The expectation of $\mathcal{H}(\mathcal{N}, x, k)$ is exactly $kp$.
Nous attendons exactement $kp$ pour $\mathcal{H}(\mathcal{N}, x, k)$.
%O Then, the probability that $\mathcal{H}(\mathcal{N}, x, k)$ will deviate from the mean by more than some small constant $\psi$ is given by the Hoeffding tail bound \cite{hoeffding1963probability}, as follows,
Donc, la probabilité que $\mathcal{H}(\mathcal{N}, x, k)$ dévie de la moyenne de plus d'une petite constante $\psi$ est donnée par la borne de queue de Hoeffding~\cite{hoeffding1963probability}, comme suit,
\begin{equation}
\begin{split}
    P(\mathcal{H}(\mathcal{C}, x, k) \leq (p-\psi)k) &\leq e^{-k\mathcal{D}(p-\psi, p)}\\
    &\leq e^{-2(p-\psi)^2k}
\end{split}
\end{equation}
where $\mathcal{D}(p-\psi, p)$ est la divergence de Kullback-Leibler, measurée par
\begin{equation}
\begin{split}
    \mathcal{D}(a, b) &= a \log \frac{a}{b} + (1 - a) \log \frac{1 - a}{1 - b}
\end{split}
\end{equation}

\paragraph{Concentration de sous-martingales}
%O Let $\{X_{\{t \geq 0\}}\}$ be a sub-martingale and $|X_t - X_{t-1}| < c_t$ almost surely. Then, for all positive reals $\psi$ and all positive integers $t$, 
Soit $\{X_{\{t \geq 0\}}\}$ une sous-martingale et $|X_t - X_{t-1}| < c_t$ presque sûrement. Alors, pour tout réel positif $\psi$ et tout entier positif $t$, 
\begin{equation}
\begin{split}
P(X_t \geq X_0 + \psi) \leq e^{-\psi^2 / 2\sum_{i = 1}^{t} c_t^2}
\end{split}
\label{eq:submartingale}
\end{equation}

\subsection{Slush}
%\label{sec:analysis}
%O Slush operates in a non-Byzantine setting; that is, $f = 0$, $c = n$.
Slush opère dans une configuration non-byzantine, c'est-à-dire $f = 0$, $c = n$.
%O In this section, we will characterize the irreversibility properties of Slush (which appear in Snowflake and Snowball), as well as the precise converge rate distribution. The distribution of of both safety and liveness of Slush translate well to the Byzantine setting.
Dans cette section, nous caractériserons les propriétés d'irréversibilité de Slush (qui apparaissent dans Snowflake et Snowball), ainsi que la distribution de taux de convergence précise. La distribution de la sûreté de fonctionnement et de vitalité de Slush se traduisent bien dans une configuration byzantine.

% \begin{figure}
%     \small
% \begin{algorithmic}[1]
%     \State initialize $u.\codecolor \in \{\texttt{R},\texttt{B}\}$ for all $u\in\mathcal{N}$
%     \For{$t = 1$ to $\phi$}
%         \State $u \assign \Call{sample}{\mathcal{N}, 1}$
%         \State $\mathcal{K} \assign \Call{sample}{\mathcal{N}\backslash u, k}$
%         \State $P \assign \texttt{[}v.\codecolor\quad\textbf{for}\ v \in \mathcal{K}\texttt{]}$
%         \For{$\codecolor' \in \{\texttt{R}, \texttt{B}\}$}
%             \If{$P.\Call{count}{\codecolor'} \ge \alpha$}
%                 \State $u.\codecolor \assign \codecolor'$
%             \EndIf
%         \EndFor
%     \EndFor
% \captionof{figure}{Slush run by a global scheduler.}\label{fig:slush_protocol_simulator}
% \end{algorithmic}
% \end{figure}

%O The procedural version of Slush in Figure~\ref{fig:slush-loop} made use of a parameter $m$, the number of rounds that a node executes Slush queries. 
La version procédurale de Slush en figure~\ref{fig:slush-loop} faisait usage d'un paramètre $m$, le nombre de tours d'un nœud exécutant des requêtes Slush.
% To derive this parameter, we transform the protocol execution from a procedural and concurrent version to one carried out by a scheduler, shown in Figure~\ref{fig:slush_protocol_simulator}.
%O What we ultimately want to extract is the total number of rounds $\phi$ that the scheduler will need to execute in order to guarantee that the entire network is the same color, whp.
Nous voulons en définitive extraire le nombre total de tours $\phi$ que l'ordonnanceur doit exécuter afin de garantir que l'entièreté du réseau se retrouve de la même couleur, ceci avec une forte probabilité.

%O We analyze the system mainly using a continuous time process. Let $\{X_{\{t \geq 0\}}\}$ be a CTMC.
Nous analysons le système en utilisant principalement un processus à temps continu. Soit $\{X_{\{t \geq 0\}}\}$ un processus de Markov à temps continu.
%O The state space $\mathcal{S}$ of the stochastic process is a condensed version of the full configuration space, where each state $\{0, \dots, n\}$ represents the total number of blue nodes in the system. 
L'espace d'état $\mathcal{S}$ du processus stochastique est une version condensée de tout l'espace de configuration, où chaque état $\{0, \dots, n\}$ représente le nombre total de nœuds bleus dans le système.

%O Let $\mathcal{F}_{X_s}$ be the filtration, or the history pertaining to the process, up to time $s$. This process is Markovian and time-homogeneous, conforming to 
Soit $\mathcal{F}_{X_s}$ la filtration, ou l'historique afférent au processus, jusqu'au temps $s$. Ce processus est Markovien et homogène dans le temps, se conformant à
\[
    P\{X_t = j | \mathcal{F}_{X_s}\} = P\{X_t = j | X_s\} = P\{X_t = j | X_0\}    
\]
%O Throughout the paper, we use $Q \equiv (q_{ij}, i, j \in \mathcal{S})$ notation to refer to the infinitesimal generator of the process, where death ($i \rightarrow i-1$) and birth ($i \rightarrow i+1$) rates of configuration transitions are denoted via $\mu_i$ and $\lambda_i$ ($\lambda_ i$ is distinct from the clock parameter $\lambda$, and will be clear from context). These rates are 
Dans cet article, nous utilisons la notation $Q \equiv (q_{ij}, i, j \in \mathcal{S})$ pour nous référer au générateur infinitésimal du processus, où les taux de mort ($i \rightarrow i-1$) et de naissance ($i \rightarrow i+1$) de transitions de configuration sont notées via $\mu_i$, et$\lambda_i$ ($\lambda_ i$ est disctint du paramètre d'horloge $\lambda$ et sera sorti du contexte). Ces taux sont
\[
    \begin{cases}
        \mu_i = i\ \mathcal{H}(\mathcal{N}, c-i, k, \alpha), & \text{for } i \rightarrow i - 1 \\
        \lambda_i = (c-i)\ \mathcal{H}(\mathcal{N}, i, k, \alpha), & \text{for } j \rightarrow i + 1 \\
    \end{cases}
\]
%O for $1\leq i\leq c-1$, and where $i = 0$ and $i = c$ are absorbing. Let $p_{ij}(t)$ refer to the probability of transitioning from state $i$ to $j$ at time $t$. 
pour $1\leq i\leq c-1$, et où $i = 0$ et $i = c$ sont absorbants. Soit $p_{ij}(t)$ une référence à la probabilité de transition de l'état $i$ à $j$ à l'instant $t$.
%O We always assume that 
Nous supposons toujours que
\[
    p_{ij}(t) = 
    \begin{cases}
      \lambda_it + o(t), & \text{pour } j = i + 1 \\
      \mu_it + o(t), & \text{pour } j = i - 1 \\
      1 - (\lambda_i + \mu_i)t + o(t), & \text{pour } j = i \\
      o(t), & \text{sinon }\\
    \end{cases}
\]
%O where all $o(t)$ are uniform in $i$. 
où tous les $o(t)$ sont uniformes en $i$.

%O \paragraph{Irreversibility}
\paragraph{Irreversibilité}
%We now discuss the core results of irreversibility properties of our family of protocols.
%O In Section~\ref{sec:analysis}, we discussed the loose Chvatal bound which provided intuitive understanding into the strong irreversibility dynamics of our core subsampling mechanism. In particular, once the network drifts to some majority value, it tends to revert back with only an exponentially small probability. We compute the closed-form expression for reversibility, and show that it is exponentially small.
En section ~\ref{sec:analysis}, nous avons traité de la borne \emph{loose} % HOULA
de Chtaval qui a fourni une compréhension intuitive de la dynamique de forte irréversibilité au cœur de notre mécanisme de sous-échantillonnage. En particulier, une fois que le réseau tend vers une valeur majoritaire donnée, il ne peut s'inverser qu'avec une probabilité exponentiellement petite. Nous calculons l'expression de forme fermée pour la réversibilité, et nous montrons qu'elle est exponentiellement petite.
\begin{theorem}
\label{theorem:slush_prob_convergence_minority}
%O Let $\xi_\delta$ be the probability of absorption into the all-red state ($s_0$), starting from a drift of $\delta$ (i.e. $\delta$ drift away from $n/2$). Then, assuming $\delta > 1$, 
Soit $\xi_\delta$ la probabilité d'absorption dans l'état totalement rouge ($s_0$), commençant par un drift de $\delta$ (c'est-à-dire que $\delta$ tendent à s'éloigner de $n/2$). Alors, en supposant $\delta > 1$,
\begin{equation}
\xi_\delta = 1 - \ddfrac{\sum_{l = 1}^{\delta} \prod_{i = 1}^{l-1} \mu_i^2 \prod_{j = l}^{n-l}\lambda_j}{2\sum_{l = 1}^{n/2}\prod_{i=1}^{l-1}\mu_i^2\prod_{j=l}^{n-l}\mu_j}
\end{equation}
et
% \begin{equation}
% \xi_\delta - \xi_{\delta+1} = \ddfrac{\mu_1^2\dots\mu_{\delta}^2\lambda_{\delta+1}\dots\lambda_{n-\delta}}{\Phi(\alpha, k, n)}
% \end{equation}
% where $\Phi(\alpha, k, n)$ is a constant dependent on $\alpha$, $k$, and $n$, but otherwise independent of starting configuration. 
\begin{equation}
\begin{split}
\ddfrac{\xi_{\delta} - \xi_{\delta+1}}{\xi_{\delta+1} - \xi_{\delta+2}} &= \mathcal{u}_{\delta+1} = \ddfrac{\lambda_{\delta+1}}{\mu_{\delta+1}} \\
&\approx \ddfrac{n-\delta-1 \sum_{j = \alpha}^{k}\ddfrac{(n-\delta-1)^k (\delta+1)^{k-j}}{n^{2k - j}}}{\delta+1 \sum_{j = \alpha}^{k}\ddfrac{(\delta+1)^k (n-\delta-1)^{k-j}}{n^{2k - j}}}
\end{split}
\end{equation}
%O where from now on we refer to $\mathcal{u}_{\delta+1}$ as the drift of the process. 
où à partir de maintenant nous nous référons à $\mathcal{u}_{\delta+1}$ par le drift du processus.
\end{theorem}

\begin{proof}
%O Our results are derived based on constructions from Tan~\cite{tan1976absorption}. We construct a sub-matrix of $Q$, denoted $B$, as shown in Figure~\ref{fig:matrixB}.
Nos résultats sont dérivés en se fondant sur les constructions de Tan~\cite{tan1976absorption}. Nous construisons une sous-matrice de $Q$, notée $B$, comme on le voit en figure~\ref{fig:matrixB}.
\begin{figure*}
\[B = 
\begin{bmatrix}
    -(\lambda_1 + \mu_1) & \lambda_1 & 0 & \cdots & \cdots & 0 \\
    \mu_2 & -(\lambda_2 + \mu_2) & \lambda_2 & 0 & \cdots & 0\\
    0 & \mu_3 & -(\lambda_3 + \mu_3) & \lambda_3 & \cdots & 0\\
    \vdots & \vdots & \ddots & \ddots & \ddots & \vdots\\
    \vdots & \vdots & \mu_{n-3} & -(\lambda_{n-2} + \mu_{n-2}) & \lambda_{n-3} & 0\\
    \vdots & \dots & 0 & \mu_{n-1} & -(\lambda_{n-2} + \mu_{n-2}) & \lambda_{n-2}\\
    0 & \dots & 0 & 0 & \mu_{n-1} & -(\lambda_{n-1} + \mu_{n-1})
\end{bmatrix}
\]
\caption{Matrice $B$.}
\label{fig:matrixB}
\end{figure*}
Let $W_1'$ = $(\mu_1, 0, \dots, 0)$, $W_{n-1}'$ = $(0, \dots, 0, \lambda_{n-1})$. Then, we can express $Q$ as 
\[
    Q =
    \begin{bmatrix}
        0 & \dots & 0\\
        W_1 & B & W_{n-1}\\
        0 & \dots & 0
    \end{bmatrix}
\]
%O As a reminder, the stationary distribution can be found via $\lim_{t \rightarrow \infty} P(t) = e^{Qt}$, where we have
Rappelons que la distribution stationnaire peut être trouvée \emph{via} $\lim_{t \rightarrow \infty} P(t) = e^{Qt}$, où nous avons
\[
    e^{Qt} = \sum_{i = 0}^{\infty} \frac{t^i}{i!} Q^i = \sum_{i = 0}^{\infty} \frac{t^i}{i!}
    \begin{bmatrix}
        0 & \dots & 0\\
        B^{i-1}W_1 & B^i & B^{i-1}W_{n-1}\\
        0 & \dots & 0
    \end{bmatrix}
\]
As Tan (eq. 2.3) shows, we have
Comme le montre Tan (eq. 2.3), nous avons
\[
    \xi(t) = B^{-1}\left[\sum_{i = 0}^{\infty} B^i  - \mathbb{I}_{n-1} \right] W_1
\]
%O Since we want the ultimate probabilities, we have that 
Comme nous voulons les probabilités ultimes, nous avons 
\[
    \xi = \lim_{t \rightarrow \infty} \xi(t) = -B^{-1}W_1
\]
%O We can explicitly compute $\xi_\delta$ in terms of our rates $\mu_i$ and $\lambda_i$, getting 
Nous pouvons explicitement calculer $\xi_\delta$ en termes de nos taux $\mu_i$ et $\lambda_i$, obtenant ainsi
\[
    \xi_\delta = \ddfrac{\sum_{l = 1}^{n-\delta}\prod_{i = 1}^{n-l}\mu_i \prod_{j = n-l+1}^{n-1}\lambda_j}{\sum_{l = 1}^{n}\prod_{i = 1}^{n-l}\mu_i \prod_{j = n-l+1}^{n-1}\lambda_j}
\]
%O However, we note that $u_{i} = \lambda_{n-i}$. Algebraic manipulation from this observation leads to the two equations in the theorem. This expression is strictly lower than the Chvatal bounds used in Section~\ref{sec:analysis}.
Cependant, notons que $u_{i} = \lambda_{n-i}$. La manipulation algébrique à partir de cette observation mène aux deux équations du théorème. Cette expression est strictement inférieure aux bornes de Chtaval utilisées en section~\ref{sec:analysis}.
\end{proof}

%O Using the construction for the absorption (and (ir)reversibility) probabilities as discussed previously, a natural follow up computation is in regards to \emph{mean convergence time}. 
En utilisant la construction pour les probabilités d'absorption (et d'(ir)réversibilité) précédemment traitées, il est naturel de poursuivre par un calcul concernant le \emph{temps de convergence moyen}.
%O Let $T_{z}(t) = \inf \{t \geq 0 : X_t = \{0, n\} | X_0 = z\}$, and let $\tau_z = \mathbb{E}[T_{z}(t)]$. $\tau_z$ is the mean time to reach either absorbing state, starting from state $z$, which corresponds to the mean convergence time. The next theorem characterizes this distribution.
Soit $T_{z}(t) = \inf \{t \geq 0 : X_t = \{0, n\} | X_0 = z\}$, et soit $\tau_z = \mathbb{E}[T_{z}(t)]$. $\tau_z$ est le temps moyen pour atteindre l'un ou l'autre des états absorbants, à partir de l'état $z$, qui correspond au temps moyen de convergence. Le théorème suivant caractérise cette distribution.

\begin{theorem}
\label{theorem:mean-convergence-time}
%O Let $\tau_z$ be the expected time to convergence, starting from state $z > n/2$, to any of the two converging states in the network (all-red or all-blue). Then, 
Soit $\tau_z$ le temps attendu de convergence, à partir de l'état $z > n/2$, vers l'un des deux états convergents dans le réseau (totalement rouge ou totalement bleu). Alors,
\begin{equation}
\tau_z = \ddfrac{\sum_{d = 1}^{n-1}x(d)y(d)}{2\sum_{l = 1}^{n/2}\prod_{i=1}^{l-1}\mu_i^2\prod_{j=l}^{n-l}\mu_j}
\end{equation}
%O where $x(d)$ and $y(d)$ are
où $x(d)$ et $y(d)$ sont
\begin{equation}
\begin{split}
x(d) &= \sum_{l = 1}^{\min(z, d)} \prod_{i=1}^{l-1} \mu_i \prod_{j = l}^{d-1} \lambda_j\\
y(d) &= \sum_{l = 1}^{n - d - \max(z-d, 0)} \prod_{i = d+1}^{n-l} \mu_i \prod_{j = n - l + 1}^{n - 1} \lambda_j
\end{split}
\end{equation}
\end{theorem}

\begin{proof}
%O Following the calculations from before, $-B^{-1}$ at row $z$ provides the number of traversals to each other state starting from $z$. Calculating their sum, we have our result. The above equation is the full expression of the matrix row sum. 
D'après les calculs qui précèdent, $-B^{-1}$ à la rangée $z$ fournit le nombre de traversées vers chaque autre état en partant de $z$. En calculant leur somme, nous avons notre résultat. L'équation ci-dessus est l'expression complète de la somme des rangées des matrices.
\end{proof}

%O Theorem~\ref{theorem:mean-convergence-time} leads to the next lemma that captures property P2, under the assumption that at the beginning of the protocol, one proposal has at least $\alpha$ support in the network. 
Le théorème~\ref{theorem:mean-convergence-time} mène au lemme suivant qui capture la propriété P2, en suppposant qu'au début du protocole, une proposition a un support d'au moins $\alpha$ dans le réseau.
\begin{lemma}
%O Slush reaches an absorbing state in finite time almost surely.
Slush atteint presque sûrement un état absorbant dans un temps fini.
\label{lemma:finitetermination}
\end{lemma}

\begin{proof}
%O Starting from any non-absorbing, transient state, there is a non-zero probability of being absorbed. Additionally, since termination is finite and everywhere differentiable, Theorem~\ref{theorem:mean-convergence-time} also implies that the probability of termination of any network configuration where a proposal has $\geq \alpha$ support in bounded time $t_{max}$ is strictly positive. 
En partant d'un quelconque état non-absorbant et transitoire, il y a une probabilité non nulle d'absorbtion. De plus, comme la terminaison est finie et différentiable partout, le théorème~\ref{theorem:mean-convergence-time} implique aussi que la probabilité de terminaison de toute configuration réseau où une proposition a un support $\geq \alpha$ dans un temps borné $t_{max}$ est strictement positive.
\end{proof}

\subsection{Snowflake}
\label{subsection:appendix_snowflake}
In Snowflake, the sampled set of nodes includes Byzantine nodes.
We introduce the decision function $\mathcal{D}(*)$, which is constructed by having each node also keep track of the total number of consecutive times it has sampled a majority of the same color ($\beta$). 
Finally, we introduce a function called $\mathcal{A}(\mathcal{S}_t)$, the adversarial strategy, that takes as parameters the entire configuration of the network at time $t$, as well as the next set of nodes chosen by the scheduler to execute, and as a side-effect, modifies the set of nodes $\mathcal{B}$ to some arbitrary configuration of colors.

In order for our prior framework to apply to Snowflake, we must deal with a key subtlety. 
Unlike in Slush, where it is clear that once the network has reached one of the converging states and therefore may not revert back, this no longer applies to Snowflake, since any adversary $f \geq \alpha$ has strictly positive probability of reverting the system, albeit this probability may be infinitesimally small. 
The CTMC is flexible enough to deal with a system where there is only one absorbing state, but the long-term behavior of the system is no longer meaningful since, after an infinite amount of time, the system is guaranteed to revert, violating safety. 
We could trivially bound the amount of time, and show safety using this bounded time assumption by simply characterizing the distribution of $e^{tQ}$, where $Q$ is the generator. 
However, we can make the following observation: if the probability of going from state $c$ (all-blue) to $c-1$ is exponentially small, then it will take the attacker exponential time (in expectation; note, this is a lower bound, and in reality it will take much longer) to succeed in reverting the system. 
Hence, we can assume that once all correct nodes are the same color, the attack from the adversary will terminate since it is impractical to continue an attack. 
In fact, under reasonably bounded timeframes, the variational distance between the exact approach and the approximation is very small. 
We leave details to the accompanying paper, but we briefly discuss how analysis proceeds for Snowflake. 

As stated in Section~\ref{sec:analysis}, the way to analyze the adversary using the same construction as in Slush is to condition reversibility on the first node $u$ deciding on blue, which can happen at any state (as specified by $\mathcal{D}(*)$). At that point, the adversarial strategy collapses to a single function, which is to continually vote for red. The probabilities of reversibility, for all states $\{1, \dots, c-1\}$ must encode the probability that additional blue nodes commit, and the single function of the adversary. The birth and death rates are transformed as follows:
\[
    \begin{cases}
        \mu_i = &i(1 - \mathbb{I}[\mathcal{D}(*, i, \mathbb{B})])\ \mathcal{H}(\mathcal{N}, c-i + f, k, \alpha)\\
        \lambda_i = &(c-i)(1 - \mathbb{I}[\mathcal{D}(*, c-i, \mathbb{R})])\ \mathcal{H}(\mathcal{N}, i, k, \alpha)\\
    \end{cases}
\]
From here on, the analysis is the same as in Slush. Under various $k$ and $\beta$, we can find the minimal $\alpha$ that provides the system strong irreversibility properties. 

The next lemma captures P3, and the proof follows from central limit theorem. 
\begin{lemma}
If $f < \Oh{\sqrt{n}}$, and $\alpha = \floor{k/2} + 1$, then Snowflake terminates in $\Oh{\log n}$ rounds with high probability. 
\label{lemma:centrallimit}
\end{lemma}
\begin{proof}
The results follows from central limit theorem, wherein for $\alpha = \floor{k/2} + 1$, the expected bias in the network after sampling will be $\Oh{\sqrt{n}}$. An adversary smaller than this bias will be unable to keep the network in a fully-bivalent state for more than a constant number of rounds. The logarithmic factor remains from the mixing time lower bound. 
\end{proof}

\subsection{Snowball}
We make the following observation: if the confidences between red and blue are equal, then the adversary has the same identical leverage in the irreversibility of the system as in Snowflake, regardless of network configuration. In fact, Snowflake can be viewed as Snowball but where drifts in confidences never exceed one. The same analysis applies to Snowball as in Snowflake, with the additional requirement of bounding the long-term behavior of the confidences in the network. To that end, analysis follows using martingale concentration inequalities, in particular the one introduced in Equation~\ref{eq:submartingale}. Snowball can be viewed as a two-urn system, where each urn is a sub-martingale. The guarantees that can be extracted hereon are that the confidences of the majority committed value (in our frame of reference is always blue), grow always more than those of the minority value, with high probability, drifting away as $t \rightarrow t_{max}$. 
\subsection{Safe Early Commitment}
As we reasoned previously, each conflict set in Avalanche can be viewed as an instance of Snowball, where each progeny instance iteratively votes for the entire path of the ancestry.
This feature provides various benefits; however, it also can lead to some virtuous transactions that depend on a rogue transaction to suffer the fate of the latter.
%has the drawback that it can entangle the fate of some unfortunate virtuous transactions with the fate of rogue ones.
In particular, rogue transactions can interject in-between virtuous transactions and reduce the ability of the virtuous transactions to ever reach the required $\textsc{isAccepted}$ predicate.
As a thought experiment, suppose that a transaction $T_i$ names a set of parent transactions that are all decided, as per local view.
If $T_i$ is sampled over a large enough set of successful queries without discovering any conflicts, then, since by assumption the entire ancestry of $T_i$ is decided, it must be the case (probabilistically) that we have achieved irreversibility.

To then statistically measure the assuredness that $T_i$ has been accepted by a large percentage of correct nodes without any conflicts, we make use of a one-way birth process, where a birth occurs when a new correct node discovers the conflict of $T_i$. Necessarily, deaths cannot exist in this model, because a conflicting transaction cannot be unseen once a correct node discovers it. 
% Let $t = 0$ be the time when $T_j$, which conflicts with $T_i$, is introduced to a single correct node $u$.
% Let $s_x$, for $x = 1$ to $c$, be the state where the number of correct nodes that know about $T_j$ is $x$, and let $p(s_x)$ be the probability of birth at state $s_x$. Then, we have:
Our births are as follows:
\begin{equation}
    \lambda_i = \frac{c - i}{c} \left(1 - \frac{{n - i \choose k}}{{n \choose k}}\right)
\end{equation}
Solving for the expected time to reach the final birth state provides a lower bound to the $\beta_1$ parameter in the $\textsc{isAccepted}$ fast-decision branch. The table below shows an example of the analysis for $n = 2000$, $\alpha = 0.8k$, and various $k$, where $\varepsilon \ll 10^{-9}$, and where $\beta$ is the minimum required value before deciding.
\begin{table}[h!]
    \small
	\centering
	\begin{tabular}{llllll}
		$k$   & 10 & 20 & 30 & 40 \\ \hline
		$\beta$ & 10.87625 & 10.50125 & 10.37625 & 10.25125
	\end{tabular}
	\label{table:fast-path-beta}
\end{table}
% \begin{figure}
%     \includegraphics[width=\linewidth]{figures/fast-path-beta.pdf}
%     \captionof{figure}{An example of $\beta$ solutions for different $k$, with $n = 2000, \alpha = 0.8k$.}
%     \label{fig:fast-path-beta}
% \end{figure}
\noindent Overall, a very small number of iterations are sufficient for the safe early commitment predicate. This supports the choice of $\beta$ in our evaluation.

\subsection{Initialization Heuristic}
\label{sec:sync-heuristic}
To improve liveness, we can use strong synchrony assumptions. The heuristic works as follows. Every node operates in two phases: in the first phase, it gossips and collects proposals for $\Oh{\log{n}}$ rounds, where each round lasts for the maximum message delay, which ensures the proposal from a correct node will propagate to almost all other correct nodes; in the second phase, each node stops collecting proposals, and gossips the existing proposals for an additional $\Oh{\log{n}}$ rounds so that every correct node ends up with approximately the same set of proposals. Finally, each node samples for the proposals it knows of locally, checking for those that have an $\alpha$ majority, ordered deterministically, such as by hash values. It then selects the first value by the order as its initial state when it starts the actual consensus protocol.
In a cryptocurrency setting, the deterministic ordering function would incorporate fees paid out for every new proposal, which means that the adversary is financially limited in its ability to launch a fairness attack against the initialization.

\subsection{Churn and View Discrepancy}\label{sec:full-analysis-churn}

Realistic systems need to accommodate the departure and arrival of nodes.
Up to now, we simplified our analysis by assuming a precise knowledge of network membership, i.e. $\mathcal{L}(u) = \mathcal{N}$.
We now demonstrate that correct nodes can admit a well-characterized amount of churn, by showing how to pick parameters such that Avalanche nodes can differ in their view of the network and still safely make decisions.

{\color{black} 

To characterize churn we use a generalized set intersection construction that allows us to make arguments about worst-case network view splits. Before formalizing it, we provide the intuition: suppose we split the network into two entirely independent, but fully connected, subsets. Clearly, the Byzantine adversary wins with probability one since it can send two conflicting transactions to the two independent networks respectively, and they would finalize the transactions immediately. This represents the worst case view split. 
\begin{figure}
\centering
\includegraphics[width=0.8\linewidth]{figures/network_view.pdf}
\caption{Changes in network view based on $S_d$'s size. All prior proofs up to now represent the variant where $S_a = S_b = \emptyset$. With the new construction, the probability of safety violation is simply a direct application of the prior sets of proofs under the new subsets.}
\label{fig:network_view}
\end{figure}
We can generalize this to arbitrary network splits, which can even be applied recursively in each subset. The proofs of safety then are a matter of characterizing the probability of red and blue committing into the two (possibly independent) subsets.

Suppose we divide the set of correct nodes into three subsets, $S_a$, $S_d$, $S_b$. We overload $\mathcal{L}(S_{*})$ to represent the views of any node within the input set. The view of all nodes in $S_a$ is $\mathcal{L}(S_a) = S_a \cup S_d \cup \mathcal{B}$, the view of all nodes in $S_b$ is $\mathcal{L}(S_b) = S_b \cup S_d \cup \mathcal{B}$, and the view of $S_d$ is $\mathcal{N}$. We assume the worst case, which means that adversarial nodes are common to all subsets. When $S_d = \emptyset$, this represents a division of the network into two equal subsets where $|S_a| = |S_b| = n/2$~\footnote{$|S_a|$ and $|S_b|$ do not have to be equal, we assume so as a demonstration.}. If $S_d$ is all correct nodes, then $|S_a| = |S_b| = n$. This construction is visually demonstrated in Figure~\ref{fig:network_view}. 

\begin{lemma}
Let $\tau \in \mathbb{Z}^{+}$. Let $|S_d| = n - \tau$, and thus $|S_{\{a, b\}}| = \tau/2$. There exists some maximal size of $\tau$ such that probability of any two nodes $u, v \in S_a,\ S_b,\ S_d$ finalizing equivocating transactions is less than $\epsilon$. 
\end{lemma}
\begin{proof}
We assume that the adversary has full control of the network view splits, meaning that they choose in full how to create $S_a,\ S_b,\ S_d$. To prove safety, we simply reuse the same exact construction as in Subsection~\ref{subsection:appendix_snowflake}, but we replace the original set $\mathcal{N}$ with a new set of interest, namely $S_a \cup S_d \cup \mathcal{B}$ (i.e., we exclude $S_b$)~\footnote{Sets are symmetric in this example.}. To thus find the maximal $\tau$, we simply replace $u_i$ and $\lambda_i$ with 
\begin{equation}
    \begin{cases}
        \bar \mu_i = i\ \mathcal{H}(S_a \cup S_d \cup \mathcal{B}, c-(\tau/2)-i, k, \alpha), & \text{for } i \rightarrow i - 1 \\
        \lambda_i = (c-i)\ \mathcal{H}(S_a \cup S_d \cup \mathcal{B}, i, k, \alpha), & \text{for } j \rightarrow i + 1 \\
    \end{cases}
\end{equation}
where
\begin{equation}
\begin{split}
P(\mathcal{H}&(S_a \cup S_d \cup \mathcal{B}, x, k) \geq \alpha)\\
&= \left.\sum_{j = \alpha}^{k} {x \choose j}{c-(\tau/2)-x \choose k-j}\middle/{c - (\tau/2) \choose k}\right.\\
\end{split}
\end{equation}
and apply the same construction as in Subsection~\ref{subsection:appendix_snowflake}. As $\tau$ increases, it is clear that $S_a$ (and conversely, $S_b$), become more independent and less reliant on the values proposed by members in $S_d$, thus incrementing the ability of the adversaries. 
\end{proof}


}


% Consider a network whose operation is divided into epochs of length $\tau$, and a view update from epoch $t$ to $t+1$ during which $\gamma$ nodes join the network and $\bar \gamma$ nodes depart.
% Under our static construction, the state space $\mathcal{S}_t$ of the network had a key parameter $\Delta^{t}$ at time $t$, induced by $c^{t}, f^{t}, n^{t}$ and the chosen security parameters.
% Churn can, at worst, impact the network by adding $\gamma$ nodes of color $\mathtt{B}$, and remove $\bar \gamma$ nodes of color $\mathtt{R}$.
% At time $t+1$, $n^{t+1} = n^{t} + \gamma - {\bar \gamma}$, while $f^{t+1}$ and $c^{t+1}$ will be modified by an amount $\leq \gamma - {\bar \gamma}$, and thus induce a new $\Delta^{t+1}$ for the chosen security parameters.
% This new $\Delta^{t+1}$ has to be chosen such that the probability of reversibility from state $c^{t+1}/2 + \Delta^{t+1} - \gamma$ is $\leq \varepsilon$, which ensures that the system will converge under the previous pessimal assumptions. The system designer can easily do this by picking an upper bound on $\gamma, \bar \gamma$.

% The final step in assuring the correctness of a view change is to account for a mix of nodes that straddle the $\tau$ boundary. We would like the network to avoid an unsafe state no matter which nodes are using the old and the new views.
% The easiest way to do this is to determine $\Delta^t$ and $\Delta^{t+1}$ for desired bounds on $\gamma, \bar \gamma$, and then to use the conservative value $\Delta^{t+1}$ during epoch $t$. In essence, this ensures that no commitments are made in configuration $\mathcal{S}_t$ unless they conservatively fulfill the safety criteria in state space $\mathcal{S}_{t+1}$. As a result, there is no possibility of a node deciding red at time $t$, the network going through an epoch change and finding itself to the left of the new irreversibility state $\Delta^{t+1}$.

% This approach trades off some of the feasibility space, to add the ability to accommodate $\gamma, \bar \gamma$ node churn per epoch.
% Overall, if $\tau$ is in excess of the time required for a decision (on the order of minutes to hours), and nodes are loosely synchronized,
% they can add or drop up to $\gamma, \bar \gamma$ nodes in each epoch using the conservative process described above.
% % Due to space reasons,
% We leave the precise method of entering and exiting the network by staking and unstaking to a subsequent paper, and instead
% rely on a membership oracle that acts as a sequencer and $\gamma$-rate-limiter, using technologies like Fireflies~\cite{JohansenRVJ15}.
% and Ethereum~\cite{wood2014ethereum}.
\end{appendices}
\end{document}
